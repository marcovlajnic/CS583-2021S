{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 4: Build a CNN for image recognition.\n",
    "\n",
    "### Name: [Marco Vlajnic]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    \n",
    "    result = numpy.zeros(shape=(y.shape[0],num_class))\n",
    "    for i in range(y.shape[0]):\n",
    "        result[i][y[i]]=1 \n",
    "    return result\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        9472      \n",
      "_________________________________________________________________\n",
      "functional_1 (Functional)    (None, 32, 32, 64)        74368     \n",
      "_________________________________________________________________\n",
      "functional_3 (Functional)    (None, 32, 32, 64)        74368     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "functional_5 (Functional)    (None, 16, 16, 64)        74368     \n",
      "_________________________________________________________________\n",
      "functional_7 (Functional)    (None, 16, 16, 64)        74368     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "functional_9 (Functional)    (None, 8, 8, 64)          74368     \n",
      "_________________________________________________________________\n",
      "functional_11 (Functional)   (None, 8, 8, 64)          74368     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 614,026\n",
      "Trainable params: 611,978\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Image generator for training\n",
    "def make_generator(X):\n",
    "    gen = ImageDataGenerator(\n",
    "            rotation_range=40,\n",
    "            zoom_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=True,\n",
    "    )\n",
    "    gen.fit(X)\n",
    "    return gen\n",
    "\n",
    "# Create a generator for the training data\n",
    "gen = make_generator(x_tr)\n",
    "\n",
    "def add_skip_connection(model, input_shape=None):\n",
    "    input_shape = input_shape or model.output_shape[1:]\n",
    "    \n",
    "    # Input to the residual block\n",
    "    x = Input(shape=input_shape)\n",
    "    \n",
    "    trace = Sequential()\n",
    "    \n",
    "    trace.add(BatchNormalization(input_shape=input_shape))\n",
    "    trace.add(Activation('relu'))\n",
    "    trace.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "    \n",
    "    trace.add(BatchNormalization())\n",
    "    trace.add(Activation('relu'))\n",
    "    trace.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "    \n",
    "    y = trace(x)\n",
    "    \n",
    "    residual_block = Model(x, Add()([x, y]))\n",
    "    \n",
    "    model.add(residual_block)\n",
    "    \n",
    "\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(64, (7, 7), padding='same', input_shape=(32, 32, 3)))\n",
    "    \n",
    "    # We will reduce the dimensionality 3 times\n",
    "    for _ in range(3):\n",
    "        # At each level, we will have three tiers of residual blocks\n",
    "        for _ in range(2):\n",
    "            add_skip_connection(model)\n",
    "            \n",
    "        # We will also reduce to half size\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 2E-4 # to be tuned!\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 1348s 1s/step - loss: 1.0059 - acc: 0.6592 - val_loss: 0.9592 - val_acc: 0.6559\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 1320s 1s/step - loss: 0.9955 - acc: 0.6640 - val_loss: 0.7886 - val_acc: 0.7359\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 1377s 1s/step - loss: 0.9911 - acc: 0.6647 - val_loss: 0.8570 - val_acc: 0.7118\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 1345s 1s/step - loss: 0.9707 - acc: 0.6722 - val_loss: 0.9627 - val_acc: 0.6581\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 1421s 1s/step - loss: 0.9708 - acc: 0.6735 - val_loss: 0.8389 - val_acc: 0.7206\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 1299s 1s/step - loss: 0.9599 - acc: 0.6746 - val_loss: 0.8192 - val_acc: 0.7302\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 1284s 1s/step - loss: 0.9598 - acc: 0.6775 - val_loss: 0.9184 - val_acc: 0.6793\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 1319s 1s/step - loss: 0.9447 - acc: 0.6813 - val_loss: 1.0066 - val_acc: 0.6382\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 1363s 1s/step - loss: 0.9448 - acc: 0.6819 - val_loss: 0.8455 - val_acc: 0.6996\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 1416s 1s/step - loss: 0.9251 - acc: 0.6876 - val_loss: 0.8224 - val_acc: 0.7186\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(gen.flow(x_tr, y_tr, batch_size=32),\n",
    "                              steps_per_epoch=len(x_tr) // 32, epochs=10,\n",
    "                              validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 1661s 1s/step - loss: 2.1569 - acc: 0.1743\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 1530s 979ms/step - loss: 1.7917 - acc: 0.2742\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 1491s 954ms/step - loss: 1.6206 - acc: 0.3483\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 1501s 960ms/step - loss: 1.4878 - acc: 0.4112\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 1491s 954ms/step - loss: 1.3903 - acc: 0.4633\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 1500s 959ms/step - loss: 1.3086 - acc: 0.5071\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 1488s 952ms/step - loss: 1.2300 - acc: 0.5485\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 1490s 953ms/step - loss: 1.1593 - acc: 0.5862\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 1498s 958ms/step - loss: 1.0970 - acc: 0.6142\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 1568s 1s/step - loss: 1.0290 - acc: 0.6404\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train_vec, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 60s 191ms/step - loss: 1.1299 - acc: 0.5890\n",
      "loss = 1.1298677921295166\n",
      "accuracy = 0.5889999866485596\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
