{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus1: Parallel Algorithms\n",
    "\n",
    "### Name: [Marco Vlajnic]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read the lecture note: [click here](https://github.com/wangshusen/DeepLearning/blob/master/LectureNotes/Parallel/Parallel.pdf)\n",
    "\n",
    "2. Implement federated averaging or decentralized optimization.\n",
    "\n",
    "3. Plot the convergence curve. (The x-axis can be ```number of epochs``` or ```number of communication```. You must make sure the label is correct.)\n",
    "\n",
    "4. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain **the code** and **the output after execution**.\n",
    "    \n",
    "5. Upload this .HTML file to your Google Drive, Dropbox, or your Github repo. (If it is submitted to Google Drive or Dropbox, you must make the file open-access.)\n",
    "\n",
    "6. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/Bonus1/Bonus1.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data processing\n",
    "\n",
    "- Download the Diabete dataset from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\n",
    "- Load the data using sklearn.\n",
    "- Preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (768, 8)\n",
      "Shape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy\n",
    "\n",
    "x_sparse, y = datasets.load_svmlight_file('diabetes')\n",
    "x = x_sparse.todense()\n",
    "\n",
    "print('Shape of x: ' + str(x.shape))\n",
    "print('Shape of y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Partition to training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 8)\n",
      "Shape of x_test: (128, 8)\n",
      "Shape of y_train: (640, 1)\n",
      "Shape of y_test: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "# partition the data to training and test sets\n",
    "n = x.shape[0]\n",
    "n_train = 640\n",
    "n_test = n - n_train\n",
    "\n",
    "rand_indices = numpy.random.permutation(n)\n",
    "train_indices = rand_indices[0:n_train]\n",
    "test_indices = rand_indices[n_train:n]\n",
    "\n",
    "x_train = x[train_indices, :]\n",
    "x_test = x[test_indices, :]\n",
    "y_train = y[train_indices].reshape(n_train, 1)\n",
    "y_test = y[test_indices].reshape(n_test, 1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the standardization to trainsform both training and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean = \n",
      "[[-0.00323034  0.05359982 -0.01078965  0.1202046   0.13885194  0.06861061\n",
      "   0.00579172 -0.09853233]]\n",
      "test std = \n",
      "[[0.96679048 1.03719549 0.93468997 0.96629787 1.04819871 0.99932649\n",
      "  1.13444297 0.87943857]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "import numpy\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / (sig + 1E-6)\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / (sig + 1E-6)\n",
    "\n",
    "print('test mean = ')\n",
    "print(numpy.mean(x_test, axis=0))\n",
    "\n",
    "print('test std = ')\n",
    "print(numpy.std(x_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Add a dimension of all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 9)\n",
      "Shape of x_test: (128, 9)\n"
     ]
    }
   ],
   "source": [
    "n_train, d = x_train.shape\n",
    "x_train = numpy.concatenate((x_train, numpy.ones((n_train, 1))), axis=1)\n",
    "\n",
    "n_test, d = x_test.shape\n",
    "x_test = numpy.concatenate((x_test, numpy.ones((n_test, 1))), axis=1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker:\n",
    "    def __init__(self , x, y): \n",
    "        self.x = x # s—by—d local feature matrix \n",
    "        self.y = y # s—by-1 local label matrix \n",
    "        self.s = x. shape [0] # number of local samples \n",
    "        self.d = x. shape [1] # number of features \n",
    "        self.w = numpy. zeros ((d, 1)) # d—by-1 model parameter vector \n",
    "\n",
    "    # Set the model parameters to the latest \n",
    "    def set_param(self ,w): \n",
    "        self.w = w \n",
    "\n",
    "    # Compute the local loss \n",
    "    def loss(self): \n",
    "        yx = numpy.multiply(self.y, self.x) # s—by—d matrix \n",
    "        yxw = numpy.dot(yx, self.w) # s—by-1 matrix \n",
    "        vecl = numpy.exp(-(yxw)) # s—by-1 matrix \n",
    "        vec2 = numpy.log (1 + vecl) # s—by-1 matrix \n",
    "        return numpy.sum(vec2) # loss function \n",
    "\n",
    "    # Compute the local gradient \n",
    "    def gradient(self,q): \n",
    "        yx = numpy.multiply (self.y, self.x) # s—by—d matrix \n",
    "        yxw = numpy.dot (yx, self.w) # s—by-1 matrix \n",
    "        vecl = numpy.exp(yxw) # s—by-1 matrix \n",
    "        vec2 = numpy.divide(yx, 1+vecl) # s—by—d matrix \n",
    "        g = -numpy.sum(vec2,axis=0).reshape(self.d, 1) # d—by-1 matrix return g \n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server : \n",
    "    def __init__ (self , m, n, d): \n",
    "        self.m = m # number of worker nodes \n",
    "        self.n = n # number of training samples \n",
    "        self.d = d # number of features \n",
    "        self.w = numpy.zeros ((d, 1)) # # d—by-1 model parameter vector \n",
    "        self.g = numpy.zeros ((d, 1)) # d—by-1 gradient \n",
    "        self.v = numpy.zeros ((d, 1)) # d—by —1 momentum \n",
    "        self. loss = 0 # loss function value \n",
    "        self. obj = 0 # objective function value \n",
    "        \n",
    "    def broadcast ( self ) : \n",
    "        return self.w \n",
    "\n",
    "# Sum the gradients and loss functions evaluated by the workers \n",
    "# Args: \n",
    "    # grads : a list of d—by-1 vectors\n",
    "    # losses : a list of scalars \n",
    "    \n",
    "    def aggregate (self , grads , losses ) : \n",
    "        self.g = numpy.zeros (( self.d, 1)) \n",
    "        self.loss = 0 \n",
    "        for k in range( self.m) : \n",
    "            #print(self.g)\n",
    "            #print(\"----\")\n",
    "            #print(grads[k])\n",
    "            self.g += grads[k] \n",
    "            self.loss += losses[k] \n",
    "            \n",
    "# Compute the gradient (from the loss and regularization ) \n",
    "    def gradient ( self , lam) : \n",
    "        self.g = self.g / self.n + lam * self.w \n",
    "        \n",
    "# Compute the objective function (sum of loss and regularization ) \n",
    "    def objective ( self , lam) : \n",
    "        reg = lam / 2 * numpy.sum( self.w * self.w) \n",
    "        self.obj = self.loss / self.n + reg \n",
    "        return self.obj \n",
    "    \n",
    "# Update the model parameters using accelerated gradient descent \n",
    "# Args: \n",
    "    # alpha: learning rate (step size ) \n",
    "    # beta : momentum parameter \n",
    "    def agd( self , alpha , beta) : \n",
    "        self.v *= beta \n",
    "        self.v += self.g \n",
    "        self.w -= alpha * self.v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "# Create a server and m worker nodes \n",
    "def create_server_workers (m, x, y) : \n",
    "    n, d = x. shape \n",
    "    s = math. floor (n / m) \n",
    "    server = Server (m, n, d) \n",
    "    workers = [] \n",
    "    for i in range (m) : \n",
    "        indices = list (range(i*s , (i+1)*s)) \n",
    "        worker = Worker(x [ indices , :] , y [ indices , :]) \n",
    "        workers . append ( worker ) \n",
    "    return server , workers \n",
    "\n",
    " \n",
    "m = 4 # number of worker nodes \n",
    "server , workers = create_server_workers (m, x_train , y_train ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function value = 0.6931471805599453\n",
      "Objective function value = 0.6813122877402906\n",
      "Objective function value = 0.6605211297303729\n",
      "Objective function value = 0.6344570003119753\n",
      "Objective function value = 0.6067852655780778\n",
      "Objective function value = 0.5804697020875905\n",
      "Objective function value = 0.5574074304105576\n",
      "Objective function value = 0.538433131002964\n",
      "Objective function value = 0.5235736416856072\n",
      "Objective function value = 0.5123747395689899\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6 # regularization parameter \n",
    "alpha = 1E-1 # learning rate \n",
    "beta = 0.9 # momentum parameter \n",
    "max_epoch = 10 # number of epochs \n",
    "for t in range (max_epoch) : \n",
    "    # step 1: broadcast \n",
    "    w = server.broadcast() \n",
    "    for i in range (m) : \n",
    "        workers[ i ].set_param (w) \n",
    "\n",
    "    # step 2: workers' local computations \n",
    "    grads = [] \n",
    "    losses = [] \n",
    "    q=1\n",
    "    for i in range (m) : \n",
    "        g = workers[i].gradient(q)\n",
    "        grads.append(g) \n",
    "        l = workers[i].loss() \n",
    "        losses.append( l ) \n",
    "    #print(\"grad\" + str(grads))\n",
    "    # step 3: aggregate the workers ' outputs \n",
    "    server.aggregate( grads , losses) \n",
    "\n",
    "    # step 4: server update the model parameters \n",
    "    server.gradient(lam) # compute gradient \n",
    "    obj = server.objective (lam) # compute compute objective function \n",
    "    print ('Objective function value = ' + str (obj) ) \n",
    "    server.agd (alpha , beta) # updates the model parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective function value\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     objective function value (scalar)\n",
    "def objective(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(-yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.log(1 + vec1) # n-by-1 matrix\n",
    "    loss = numpy.mean(vec2) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    return loss + reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial objective function value = 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "# initialize w\n",
    "d = x_train.shape[1]\n",
    "w = numpy.zeros((d, 1))\n",
    "\n",
    "# evaluate the objective function value at w\n",
    "lam = 1E-6\n",
    "objval0 = objective(w, x_train, y_train, lam)\n",
    "print('Initial objective function value = ' + str(objval0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradient\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     g: g: d-by-1 matrix, full gradient\n",
    "def gradient(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.divide(yx, 1+vec1) # n-by-d matrix\n",
    "    vec3 = -numpy.mean(vec2, axis=0).reshape(d, 1) # d-by-1 matrix\n",
    "    g = vec3 + lam * w\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_iter: integer, the maximal iterations\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: d-by-1 matrix, the solution\n",
    "#     objvals: a record of each iteration's objective value\n",
    "def grad_descent(x, y, lam, stepsize, max_iter=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_iter) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_iter):\n",
    "        objval = objective(w, x, y, lam)\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at t=' + str(t) + ' is ' + str(objval))\n",
    "        g = gradient(w, x, y, lam)\n",
    "        w -= stepsize * g\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at t=0 is 0.6931471805599453\n",
      "Objective value at t=1 is 0.5953857774467942\n",
      "Objective value at t=2 is 0.5532743331853398\n",
      "Objective value at t=3 is 0.5303900600746227\n",
      "Objective value at t=4 is 0.516173418960837\n",
      "Objective value at t=5 is 0.506638571856765\n",
      "Objective value at t=6 is 0.49992890916111216\n",
      "Objective value at t=7 is 0.49504970272197096\n",
      "Objective value at t=8 is 0.4914152314327289\n",
      "Objective value at t=9 is 0.4886572259553177\n",
      "Objective value at t=10 is 0.4865329241110372\n",
      "Objective value at t=11 is 0.4848765087422553\n",
      "Objective value at t=12 is 0.4835715270847315\n",
      "Objective value at t=13 is 0.48253433177265015\n",
      "Objective value at t=14 is 0.48170370048621675\n",
      "Objective value at t=15 is 0.4810341015599543\n",
      "Objective value at t=16 is 0.48049120078337587\n",
      "Objective value at t=17 is 0.48004879229757874\n",
      "Objective value at t=18 is 0.47968665958709567\n",
      "Objective value at t=19 is 0.47938905823785755\n",
      "Objective value at t=20 is 0.4791436228062268\n",
      "Objective value at t=21 is 0.47894056816105846\n",
      "Objective value at t=22 is 0.4787720985591265\n",
      "Objective value at t=23 is 0.47863196538173663\n",
      "Objective value at t=24 is 0.47851513265786955\n",
      "Objective value at t=25 is 0.47841752167908974\n",
      "Objective value at t=26 is 0.4783358142932569\n",
      "Objective value at t=27 is 0.4782673001770477\n",
      "Objective value at t=28 is 0.4782097573808383\n",
      "Objective value at t=29 is 0.4781613582656077\n",
      "Objective value at t=30 is 0.4781205949745059\n",
      "Objective value at t=31 is 0.47808622004537665\n",
      "Objective value at t=32 is 0.47805719884016323\n",
      "Objective value at t=33 is 0.4780326712561971\n",
      "Objective value at t=34 is 0.4780119207716468\n",
      "Objective value at t=35 is 0.4779943493181506\n",
      "Objective value at t=36 is 0.47797945680701864\n",
      "Objective value at t=37 is 0.47796682438942\n",
      "Objective value at t=38 is 0.47795610072588574\n",
      "Objective value at t=39 is 0.477946990691004\n",
      "Objective value at t=40 is 0.4779392460561792\n",
      "Objective value at t=41 is 0.47793265778477984\n",
      "Objective value at t=42 is 0.47792704964588417\n",
      "Objective value at t=43 is 0.4779222729096157\n",
      "Objective value at t=44 is 0.4779182019321542\n",
      "Objective value at t=45 is 0.47791473047445576\n",
      "Objective value at t=46 is 0.47791176862752477\n",
      "Objective value at t=47 is 0.47790924024023484\n",
      "Objective value at t=48 is 0.4779070807644009\n",
      "Objective value at t=49 is 0.4779052354469477\n",
      "Objective value at t=50 is 0.47790365781133665\n",
      "Objective value at t=51 is 0.47790230838045494\n",
      "Objective value at t=52 is 0.47790115360137825\n",
      "Objective value at t=53 is 0.47790016493916\n",
      "Objective value at t=54 is 0.47789931811233066\n",
      "Objective value at t=55 is 0.4778985924473574\n",
      "Objective value at t=56 is 0.47789797033308673\n",
      "Objective value at t=57 is 0.47789743675930835\n",
      "Objective value at t=58 is 0.4778969789261711\n",
      "Objective value at t=59 is 0.4778965859133339\n",
      "Objective value at t=60 is 0.47789624839952105\n",
      "Objective value at t=61 is 0.4778959584246474\n",
      "Objective value at t=62 is 0.4778957091879285\n",
      "Objective value at t=63 is 0.47789549487642563\n",
      "Objective value at t=64 is 0.47789531051935813\n",
      "Objective value at t=65 is 0.47789515186424114\n",
      "Objective value at t=66 is 0.47789501527152217\n",
      "Objective value at t=67 is 0.47789489762491105\n",
      "Objective value at t=68 is 0.4778947962550248\n",
      "Objective value at t=69 is 0.47789470887434143\n",
      "Objective value at t=70 is 0.4778946335217609\n",
      "Objective value at t=71 is 0.4778945685153326\n",
      "Objective value at t=72 is 0.4778945124119292\n",
      "Objective value at t=73 is 0.4778944639728302\n",
      "Objective value at t=74 is 0.47789442213433736\n",
      "Objective value at t=75 is 0.4778943859826748\n",
      "Objective value at t=76 is 0.4778943547325422\n",
      "Objective value at t=77 is 0.47789432770877804\n",
      "Objective value at t=78 is 0.47789430433068\n",
      "Objective value at t=79 is 0.47789428409858875\n",
      "Objective value at t=80 is 0.47789426658240547\n",
      "Objective value at t=81 is 0.4778942514117595\n",
      "Objective value at t=82 is 0.47789423826758703\n",
      "Objective value at t=83 is 0.4778942268749138\n",
      "Objective value at t=84 is 0.47789421699666834\n",
      "Objective value at t=85 is 0.4778942084283766\n",
      "Objective value at t=86 is 0.4778942009936094\n",
      "Objective value at t=87 is 0.4778941945400768\n",
      "Objective value at t=88 is 0.4778941889362724\n",
      "Objective value at t=89 is 0.4778941840685934\n",
      "Objective value at t=90 is 0.47789417983886434\n",
      "Objective value at t=91 is 0.4778941761622089\n",
      "Objective value at t=92 is 0.4778941729652205\n",
      "Objective value at t=93 is 0.4778941701843874\n",
      "Objective value at t=94 is 0.4778941677647382\n",
      "Objective value at t=95 is 0.47789416565867476\n",
      "Objective value at t=96 is 0.47789416382496863\n",
      "Objective value at t=97 is 0.4778941622278941\n",
      "Objective value at t=98 is 0.47789416083648306\n",
      "Objective value at t=99 is 0.47789415962388143\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 1.0\n",
    "w, objvals_gd_q1 = grad_descent(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_i and the gradient of Q_i\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: 1-by-d matrix\n",
    "#     yi: scalar\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def stochastic_objective_gradient(w, xi, yi, lam):\n",
    "    d = xi.shape[0]\n",
    "    yx = yi * xi # 1-by-d matrix\n",
    "    yxw = float(numpy.dot(yx, w)) # scalar\n",
    "    \n",
    "    # calculate objective function Q_i\n",
    "    loss = numpy.log(1 + numpy.exp(-yxw)) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    obj = loss + reg\n",
    "    \n",
    "    # calculate stochastic gradient\n",
    "    g_loss = -yx.T / (1 + numpy.exp(yxw)) # d-by-1 matrix\n",
    "    g = g_loss + lam * w # d-by-1 matrix\n",
    "    \n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def sgd(x, y, lam, stepsize, max_epoch=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_epoch) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_epoch):\n",
    "        # randomly shuffle the samples\n",
    "        rand_indices = numpy.random.permutation(n)\n",
    "        x_rand = x[rand_indices, :]\n",
    "        y_rand = y[rand_indices, :]\n",
    "        \n",
    "        objval = 0 # accumulate the objective values\n",
    "        for i in range(n):\n",
    "            xi = x_rand[i, :] # 1-by-d matrix\n",
    "            yi = float(y_rand[i, :]) # scalar\n",
    "            obj, g = stochastic_objective_gradient(w, xi, yi, lam)\n",
    "            objval += obj\n",
    "            w -= stepsize * g\n",
    "        \n",
    "        stepsize *= 0.9 # decrease step size\n",
    "        objval /= n\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at epoch t=' + str(t) + ' is ' + str(objval))\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch t=0 is 0.5348826012643031\n",
      "Objective value at epoch t=1 is 0.5271983945340782\n",
      "Objective value at epoch t=2 is 0.5252823851711688\n",
      "Objective value at epoch t=3 is 0.5173924402667615\n",
      "Objective value at epoch t=4 is 0.5172908545289248\n",
      "Objective value at epoch t=5 is 0.49856638026774425\n",
      "Objective value at epoch t=6 is 0.5129958186044001\n",
      "Objective value at epoch t=7 is 0.5029696266802086\n",
      "Objective value at epoch t=8 is 0.5018805674207056\n",
      "Objective value at epoch t=9 is 0.4980301147964261\n",
      "Objective value at epoch t=10 is 0.4983605314295764\n",
      "Objective value at epoch t=11 is 0.498045649291153\n",
      "Objective value at epoch t=12 is 0.4886640022700074\n",
      "Objective value at epoch t=13 is 0.49511599434625586\n",
      "Objective value at epoch t=14 is 0.49376451622601303\n",
      "Objective value at epoch t=15 is 0.49217139214204303\n",
      "Objective value at epoch t=16 is 0.48964082775434986\n",
      "Objective value at epoch t=17 is 0.487248054021702\n",
      "Objective value at epoch t=18 is 0.4869660454495003\n",
      "Objective value at epoch t=19 is 0.48797869421100765\n",
      "Objective value at epoch t=20 is 0.48578853843690106\n",
      "Objective value at epoch t=21 is 0.48379573684198096\n",
      "Objective value at epoch t=22 is 0.4852186534607853\n",
      "Objective value at epoch t=23 is 0.4837223326286021\n",
      "Objective value at epoch t=24 is 0.48324983011658756\n",
      "Objective value at epoch t=25 is 0.4823754239338559\n",
      "Objective value at epoch t=26 is 0.48275969623238746\n",
      "Objective value at epoch t=27 is 0.48183649178848736\n",
      "Objective value at epoch t=28 is 0.48161707311820157\n",
      "Objective value at epoch t=29 is 0.48125803551485263\n",
      "Objective value at epoch t=30 is 0.4808267049602997\n",
      "Objective value at epoch t=31 is 0.4803864130251201\n",
      "Objective value at epoch t=32 is 0.4804803974616698\n",
      "Objective value at epoch t=33 is 0.4801960338329393\n",
      "Objective value at epoch t=34 is 0.48001956889470093\n",
      "Objective value at epoch t=35 is 0.47975478225356954\n",
      "Objective value at epoch t=36 is 0.47961200770204826\n",
      "Objective value at epoch t=37 is 0.47942550438502335\n",
      "Objective value at epoch t=38 is 0.479276020316871\n",
      "Objective value at epoch t=39 is 0.47914795116628905\n",
      "Objective value at epoch t=40 is 0.47901621143576856\n",
      "Objective value at epoch t=41 is 0.47890117262475396\n",
      "Objective value at epoch t=42 is 0.47881011562350945\n",
      "Objective value at epoch t=43 is 0.4787011511815149\n",
      "Objective value at epoch t=44 is 0.47862366914933235\n",
      "Objective value at epoch t=45 is 0.47857179858333276\n",
      "Objective value at epoch t=46 is 0.47849772818135045\n",
      "Objective value at epoch t=47 is 0.4784394765833276\n",
      "Objective value at epoch t=48 is 0.47838382420688175\n",
      "Objective value at epoch t=49 is 0.4783368254594472\n",
      "Objective value at epoch t=50 is 0.4782911960433055\n",
      "Objective value at epoch t=51 is 0.478253576305403\n",
      "Objective value at epoch t=52 is 0.4782171747156997\n",
      "Objective value at epoch t=53 is 0.47818657012662247\n",
      "Objective value at epoch t=54 is 0.47815716883721276\n",
      "Objective value at epoch t=55 is 0.47813062377647186\n",
      "Objective value at epoch t=56 is 0.47810713024763096\n",
      "Objective value at epoch t=57 is 0.47808525121244266\n",
      "Objective value at epoch t=58 is 0.47806711684681147\n",
      "Objective value at epoch t=59 is 0.4780498203705747\n",
      "Objective value at epoch t=60 is 0.4780342682181482\n",
      "Objective value at epoch t=61 is 0.47802052101377157\n",
      "Objective value at epoch t=62 is 0.47800769770671947\n",
      "Objective value at epoch t=63 is 0.47799656487751935\n",
      "Objective value at epoch t=64 is 0.47798627310091585\n",
      "Objective value at epoch t=65 is 0.47797710729537835\n",
      "Objective value at epoch t=66 is 0.4779690018852839\n",
      "Objective value at epoch t=67 is 0.47796156616165597\n",
      "Objective value at epoch t=68 is 0.4779548592354783\n",
      "Objective value at epoch t=69 is 0.4779488634252176\n",
      "Objective value at epoch t=70 is 0.47794350463344104\n",
      "Objective value at epoch t=71 is 0.47793863329458314\n",
      "Objective value at epoch t=72 is 0.4779342248039753\n",
      "Objective value at epoch t=73 is 0.4779302985643903\n",
      "Objective value at epoch t=74 is 0.4779267362206297\n",
      "Objective value at epoch t=75 is 0.4779235508238006\n",
      "Objective value at epoch t=76 is 0.477920666954921\n",
      "Objective value at epoch t=77 is 0.47791807955615007\n",
      "Objective value at epoch t=78 is 0.4779157517234599\n",
      "Objective value at epoch t=79 is 0.4779136565884425\n",
      "Objective value at epoch t=80 is 0.47791177312406086\n",
      "Objective value at epoch t=81 is 0.4779100698724778\n",
      "Objective value at epoch t=82 is 0.4779085406266149\n",
      "Objective value at epoch t=83 is 0.47790716439100456\n",
      "Objective value at epoch t=84 is 0.4779059277663711\n",
      "Objective value at epoch t=85 is 0.47790481133822843\n",
      "Objective value at epoch t=86 is 0.47790380869461213\n",
      "Objective value at epoch t=87 is 0.47790290507926425\n",
      "Objective value at epoch t=88 is 0.477902092162022\n",
      "Objective value at epoch t=89 is 0.47790136081844725\n",
      "Objective value at epoch t=90 is 0.4779007018333733\n",
      "Objective value at epoch t=91 is 0.47790010959255236\n",
      "Objective value at epoch t=92 is 0.47789957650238496\n",
      "Objective value at epoch t=93 is 0.477899096226517\n",
      "Objective value at epoch t=94 is 0.47789866444534923\n",
      "Objective value at epoch t=95 is 0.47789827561165066\n",
      "Objective value at epoch t=96 is 0.47789792536420383\n",
      "Objective value at epoch t=97 is 0.47789761035201045\n",
      "Objective value at epoch t=98 is 0.4778973271063548\n",
      "Objective value at epoch t=99 is 0.47789707194843956\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 0.1\n",
    "w, objvals_sgd_q1 = sgd(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function value = 0.5041771126877298\n",
      "Objective function value = 0.49829915917194306\n",
      "Objective function value = 0.4941349213003136\n",
      "Objective function value = 0.4911927472916206\n",
      "Objective function value = 0.4890991720925674\n",
      "Objective function value = 0.4875855215531629\n",
      "Objective function value = 0.4864679259802882\n",
      "Objective function value = 0.4856265558465921\n",
      "Objective function value = 0.4849868970225325\n",
      "Objective function value = 0.4845042078760652\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6 # regularization parameter \n",
    "alpha = 1E-1 # learning rate \n",
    "beta = 0.9 # momentum parameter \n",
    "max_epoch = 10 # number of epochs \n",
    "for t in range (max_epoch) : \n",
    "    # step 1: broadcast \n",
    "    w = server.broadcast() \n",
    "    for i in range (m) : \n",
    "        workers[ i ].set_param (w) \n",
    "\n",
    "    # step 2: workers' local computations \n",
    "    grads = [] \n",
    "    losses = [] \n",
    "    q=8\n",
    "    for i in range (m) : \n",
    "        g = workers[i].gradient(q)\n",
    "        grads.append(g) \n",
    "        l = workers[i].loss() \n",
    "        losses.append( l ) \n",
    "    #print(\"grad\" + str(grads))\n",
    "    # step 3: aggregate the workers ' outputs \n",
    "    server.aggregate( grads , losses) \n",
    "\n",
    "    # step 4: server update the model parameters \n",
    "    server.gradient(lam) # compute gradient \n",
    "    obj = server.objective (lam) # compute compute objective function \n",
    "    print ('Objective function value = ' + str (obj) ) \n",
    "    server.agd (alpha , beta) # updates the model parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective function value\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     objective function value (scalar)\n",
    "def objective(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(-yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.log(1 + vec1) # n-by-1 matrix\n",
    "    loss = numpy.mean(vec2) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    return loss + reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial objective function value = 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "# initialize w\n",
    "d = x_train.shape[1]\n",
    "w = numpy.zeros((d, 1))\n",
    "\n",
    "# evaluate the objective function value at w\n",
    "lam = 1E-6\n",
    "objval0 = objective(w, x_train, y_train, lam)\n",
    "print('Initial objective function value = ' + str(objval0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradient\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     g: g: d-by-1 matrix, full gradient\n",
    "def gradient(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.divide(yx, 1+vec1) # n-by-d matrix\n",
    "    vec3 = -numpy.mean(vec2, axis=0).reshape(d, 1) # d-by-1 matrix\n",
    "    g = vec3 + lam * w\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_iter: integer, the maximal iterations\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: d-by-1 matrix, the solution\n",
    "#     objvals: a record of each iteration's objective value\n",
    "def grad_descent(x, y, lam, stepsize, max_iter=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_iter) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_iter):\n",
    "        objval = objective(w, x, y, lam)\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at t=' + str(t) + ' is ' + str(objval))\n",
    "        g = gradient(w, x, y, lam)\n",
    "        w -= stepsize * g\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at t=0 is 0.6931471805599453\n",
      "Objective value at t=1 is 0.5953857774467942\n",
      "Objective value at t=2 is 0.5532743331853398\n",
      "Objective value at t=3 is 0.5303900600746227\n",
      "Objective value at t=4 is 0.516173418960837\n",
      "Objective value at t=5 is 0.506638571856765\n",
      "Objective value at t=6 is 0.49992890916111216\n",
      "Objective value at t=7 is 0.49504970272197096\n",
      "Objective value at t=8 is 0.4914152314327289\n",
      "Objective value at t=9 is 0.4886572259553177\n",
      "Objective value at t=10 is 0.4865329241110372\n",
      "Objective value at t=11 is 0.4848765087422553\n",
      "Objective value at t=12 is 0.4835715270847315\n",
      "Objective value at t=13 is 0.48253433177265015\n",
      "Objective value at t=14 is 0.48170370048621675\n",
      "Objective value at t=15 is 0.4810341015599543\n",
      "Objective value at t=16 is 0.48049120078337587\n",
      "Objective value at t=17 is 0.48004879229757874\n",
      "Objective value at t=18 is 0.47968665958709567\n",
      "Objective value at t=19 is 0.47938905823785755\n",
      "Objective value at t=20 is 0.4791436228062268\n",
      "Objective value at t=21 is 0.47894056816105846\n",
      "Objective value at t=22 is 0.4787720985591265\n",
      "Objective value at t=23 is 0.47863196538173663\n",
      "Objective value at t=24 is 0.47851513265786955\n",
      "Objective value at t=25 is 0.47841752167908974\n",
      "Objective value at t=26 is 0.4783358142932569\n",
      "Objective value at t=27 is 0.4782673001770477\n",
      "Objective value at t=28 is 0.4782097573808383\n",
      "Objective value at t=29 is 0.4781613582656077\n",
      "Objective value at t=30 is 0.4781205949745059\n",
      "Objective value at t=31 is 0.47808622004537665\n",
      "Objective value at t=32 is 0.47805719884016323\n",
      "Objective value at t=33 is 0.4780326712561971\n",
      "Objective value at t=34 is 0.4780119207716468\n",
      "Objective value at t=35 is 0.4779943493181506\n",
      "Objective value at t=36 is 0.47797945680701864\n",
      "Objective value at t=37 is 0.47796682438942\n",
      "Objective value at t=38 is 0.47795610072588574\n",
      "Objective value at t=39 is 0.477946990691004\n",
      "Objective value at t=40 is 0.4779392460561792\n",
      "Objective value at t=41 is 0.47793265778477984\n",
      "Objective value at t=42 is 0.47792704964588417\n",
      "Objective value at t=43 is 0.4779222729096157\n",
      "Objective value at t=44 is 0.4779182019321542\n",
      "Objective value at t=45 is 0.47791473047445576\n",
      "Objective value at t=46 is 0.47791176862752477\n",
      "Objective value at t=47 is 0.47790924024023484\n",
      "Objective value at t=48 is 0.4779070807644009\n",
      "Objective value at t=49 is 0.4779052354469477\n",
      "Objective value at t=50 is 0.47790365781133665\n",
      "Objective value at t=51 is 0.47790230838045494\n",
      "Objective value at t=52 is 0.47790115360137825\n",
      "Objective value at t=53 is 0.47790016493916\n",
      "Objective value at t=54 is 0.47789931811233066\n",
      "Objective value at t=55 is 0.4778985924473574\n",
      "Objective value at t=56 is 0.47789797033308673\n",
      "Objective value at t=57 is 0.47789743675930835\n",
      "Objective value at t=58 is 0.4778969789261711\n",
      "Objective value at t=59 is 0.4778965859133339\n",
      "Objective value at t=60 is 0.47789624839952105\n",
      "Objective value at t=61 is 0.4778959584246474\n",
      "Objective value at t=62 is 0.4778957091879285\n",
      "Objective value at t=63 is 0.47789549487642563\n",
      "Objective value at t=64 is 0.47789531051935813\n",
      "Objective value at t=65 is 0.47789515186424114\n",
      "Objective value at t=66 is 0.47789501527152217\n",
      "Objective value at t=67 is 0.47789489762491105\n",
      "Objective value at t=68 is 0.4778947962550248\n",
      "Objective value at t=69 is 0.47789470887434143\n",
      "Objective value at t=70 is 0.4778946335217609\n",
      "Objective value at t=71 is 0.4778945685153326\n",
      "Objective value at t=72 is 0.4778945124119292\n",
      "Objective value at t=73 is 0.4778944639728302\n",
      "Objective value at t=74 is 0.47789442213433736\n",
      "Objective value at t=75 is 0.4778943859826748\n",
      "Objective value at t=76 is 0.4778943547325422\n",
      "Objective value at t=77 is 0.47789432770877804\n",
      "Objective value at t=78 is 0.47789430433068\n",
      "Objective value at t=79 is 0.47789428409858875\n",
      "Objective value at t=80 is 0.47789426658240547\n",
      "Objective value at t=81 is 0.4778942514117595\n",
      "Objective value at t=82 is 0.47789423826758703\n",
      "Objective value at t=83 is 0.4778942268749138\n",
      "Objective value at t=84 is 0.47789421699666834\n",
      "Objective value at t=85 is 0.4778942084283766\n",
      "Objective value at t=86 is 0.4778942009936094\n",
      "Objective value at t=87 is 0.4778941945400768\n",
      "Objective value at t=88 is 0.4778941889362724\n",
      "Objective value at t=89 is 0.4778941840685934\n",
      "Objective value at t=90 is 0.47789417983886434\n",
      "Objective value at t=91 is 0.4778941761622089\n",
      "Objective value at t=92 is 0.4778941729652205\n",
      "Objective value at t=93 is 0.4778941701843874\n",
      "Objective value at t=94 is 0.4778941677647382\n",
      "Objective value at t=95 is 0.47789416565867476\n",
      "Objective value at t=96 is 0.47789416382496863\n",
      "Objective value at t=97 is 0.4778941622278941\n",
      "Objective value at t=98 is 0.47789416083648306\n",
      "Objective value at t=99 is 0.47789415962388143\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 1.0\n",
    "w, objvals_gd_q8 = grad_descent(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_i and the gradient of Q_i\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: 1-by-d matrix\n",
    "#     yi: scalar\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def stochastic_objective_gradient(w, xi, yi, lam):\n",
    "    d = xi.shape[0]\n",
    "    yx = yi * xi # 1-by-d matrix\n",
    "    yxw = float(numpy.dot(yx, w)) # scalar\n",
    "    \n",
    "    # calculate objective function Q_i\n",
    "    loss = numpy.log(1 + numpy.exp(-yxw)) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    obj = loss + reg\n",
    "    \n",
    "    # calculate stochastic gradient\n",
    "    g_loss = -yx.T / (1 + numpy.exp(yxw)) # d-by-1 matrix\n",
    "    g = g_loss + lam * w # d-by-1 matrix\n",
    "    \n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def sgd(x, y, lam, stepsize, max_epoch=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_epoch) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_epoch):\n",
    "        # randomly shuffle the samples\n",
    "        rand_indices = numpy.random.permutation(n)\n",
    "        x_rand = x[rand_indices, :]\n",
    "        y_rand = y[rand_indices, :]\n",
    "        \n",
    "        objval = 0 # accumulate the objective values\n",
    "        for i in range(n):\n",
    "            xi = x_rand[i, :] # 1-by-d matrix\n",
    "            yi = float(y_rand[i, :]) # scalar\n",
    "            obj, g = stochastic_objective_gradient(w, xi, yi, lam)\n",
    "            objval += obj\n",
    "            w -= stepsize * g\n",
    "        \n",
    "        stepsize *= 0.9 # decrease step size\n",
    "        objval /= n\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at epoch t=' + str(t) + ' is ' + str(objval))\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch t=0 is 0.546562988954108\n",
      "Objective value at epoch t=1 is 0.5190554503040958\n",
      "Objective value at epoch t=2 is 0.5191296197220978\n",
      "Objective value at epoch t=3 is 0.5218654765068801\n",
      "Objective value at epoch t=4 is 0.5065063096757405\n",
      "Objective value at epoch t=5 is 0.5152142312338077\n",
      "Objective value at epoch t=6 is 0.5031984770805596\n",
      "Objective value at epoch t=7 is 0.5090731256471094\n",
      "Objective value at epoch t=8 is 0.5046736477212114\n",
      "Objective value at epoch t=9 is 0.4984767756356289\n",
      "Objective value at epoch t=10 is 0.4960134967204536\n",
      "Objective value at epoch t=11 is 0.49617918084053275\n",
      "Objective value at epoch t=12 is 0.49745386739469916\n",
      "Objective value at epoch t=13 is 0.49154031950190397\n",
      "Objective value at epoch t=14 is 0.4926916220999839\n",
      "Objective value at epoch t=15 is 0.4924886895946399\n",
      "Objective value at epoch t=16 is 0.490319201119385\n",
      "Objective value at epoch t=17 is 0.4884099200990962\n",
      "Objective value at epoch t=18 is 0.48856528738816235\n",
      "Objective value at epoch t=19 is 0.4872891107116765\n",
      "Objective value at epoch t=20 is 0.4857749840433173\n",
      "Objective value at epoch t=21 is 0.4845181716271349\n",
      "Objective value at epoch t=22 is 0.4854773719228282\n",
      "Objective value at epoch t=23 is 0.4838262892750288\n",
      "Objective value at epoch t=24 is 0.48346768108511756\n",
      "Objective value at epoch t=25 is 0.4832696738832564\n",
      "Objective value at epoch t=26 is 0.4826199577694351\n",
      "Objective value at epoch t=27 is 0.4820605677162802\n",
      "Objective value at epoch t=28 is 0.4816545721501379\n",
      "Objective value at epoch t=29 is 0.48107271824274134\n",
      "Objective value at epoch t=30 is 0.4809546402571163\n",
      "Objective value at epoch t=31 is 0.4807927194567613\n",
      "Objective value at epoch t=32 is 0.4804815267226047\n",
      "Objective value at epoch t=33 is 0.48022128385368096\n",
      "Objective value at epoch t=34 is 0.4799682080466964\n",
      "Objective value at epoch t=35 is 0.479804690735348\n",
      "Objective value at epoch t=36 is 0.47960460410109745\n",
      "Objective value at epoch t=37 is 0.4794316873298892\n",
      "Objective value at epoch t=38 is 0.4792633958692842\n",
      "Objective value at epoch t=39 is 0.47912985930236374\n",
      "Objective value at epoch t=40 is 0.4790318779829187\n",
      "Objective value at epoch t=41 is 0.47890659833138993\n",
      "Objective value at epoch t=42 is 0.4788100518450949\n",
      "Objective value at epoch t=43 is 0.47872231693588674\n",
      "Objective value at epoch t=44 is 0.4786253249974627\n",
      "Objective value at epoch t=45 is 0.47856584464407464\n",
      "Objective value at epoch t=46 is 0.47850248631000214\n",
      "Objective value at epoch t=47 is 0.47844081611120604\n",
      "Objective value at epoch t=48 is 0.4783869209193806\n",
      "Objective value at epoch t=49 is 0.47833773239646443\n",
      "Objective value at epoch t=50 is 0.4782877141204545\n",
      "Objective value at epoch t=51 is 0.47825362463457877\n",
      "Objective value at epoch t=52 is 0.47821824588198725\n",
      "Objective value at epoch t=53 is 0.4781843106350895\n",
      "Objective value at epoch t=54 is 0.4781570175363449\n",
      "Objective value at epoch t=55 is 0.4781305048678856\n",
      "Objective value at epoch t=56 is 0.4781061720583433\n",
      "Objective value at epoch t=57 is 0.4780859211280905\n",
      "Objective value at epoch t=58 is 0.4780662712269358\n",
      "Objective value at epoch t=59 is 0.47804923636960134\n",
      "Objective value at epoch t=60 is 0.47803363302440455\n",
      "Objective value at epoch t=61 is 0.4780201085457894\n",
      "Objective value at epoch t=62 is 0.47800714525487314\n",
      "Objective value at epoch t=63 is 0.47799602063781454\n",
      "Objective value at epoch t=64 is 0.47798563236838437\n",
      "Objective value at epoch t=65 is 0.47797677357469814\n",
      "Objective value at epoch t=66 is 0.4779686484291221\n",
      "Objective value at epoch t=67 is 0.4779613026199658\n",
      "Objective value at epoch t=68 is 0.47795462995051735\n",
      "Objective value at epoch t=69 is 0.47794856943569874\n",
      "Objective value at epoch t=70 is 0.47794325388481507\n",
      "Objective value at epoch t=71 is 0.47793837949702844\n",
      "Objective value at epoch t=72 is 0.47793398265230735\n",
      "Objective value at epoch t=73 is 0.47793005880299333\n",
      "Objective value at epoch t=74 is 0.4779264877635594\n",
      "Objective value at epoch t=75 is 0.47792330562369456\n",
      "Objective value at epoch t=76 is 0.4779204249255856\n",
      "Objective value at epoch t=77 is 0.4779178383255952\n",
      "Objective value at epoch t=78 is 0.4779155007016088\n",
      "Objective value at epoch t=79 is 0.47791341278608324\n",
      "Objective value at epoch t=80 is 0.4779115243809918\n",
      "Objective value at epoch t=81 is 0.4779098236622894\n",
      "Objective value at epoch t=82 is 0.4779082880708997\n",
      "Objective value at epoch t=83 is 0.4779069194698568\n",
      "Objective value at epoch t=84 is 0.47790567943478146\n",
      "Objective value at epoch t=85 is 0.47790456561881617\n",
      "Objective value at epoch t=86 is 0.4779035621585641\n",
      "Objective value at epoch t=87 is 0.47790265917682956\n",
      "Objective value at epoch t=88 is 0.4779018468366279\n",
      "Objective value at epoch t=89 is 0.47790111502833144\n",
      "Objective value at epoch t=90 is 0.4779004565046109\n",
      "Objective value at epoch t=91 is 0.4778998640820566\n",
      "Objective value at epoch t=92 is 0.47789933058863154\n",
      "Objective value at epoch t=93 is 0.47789885044591507\n",
      "Objective value at epoch t=94 is 0.477898418856135\n",
      "Objective value at epoch t=95 is 0.4778980298475778\n",
      "Objective value at epoch t=96 is 0.4778976801211936\n",
      "Objective value at epoch t=97 is 0.4778973651251322\n",
      "Objective value at epoch t=98 is 0.47789708173770606\n",
      "Objective value at epoch t=99 is 0.47789682663902067\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 0.1\n",
    "w, objvals_sgd_q8 = sgd(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-47e8d7a63a93>:12: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  line0, = plt.plot(epochs_gd_1, objvals_gd_q1, '-b', LineWidth=4)\n",
      "<ipython-input-26-47e8d7a63a93>:13: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  line1, = plt.plot(epochs_sgd_1, objvals_sgd_q1, '-r', LineWidth=2)\n",
      "<ipython-input-26-47e8d7a63a93>:14: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  line2, = plt.plot(epochs_gd_2, objvals_gd_q8, '--y', LineWidth=4)\n",
      "<ipython-input-26-47e8d7a63a93>:15: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  line3, = plt.plot(epochs_sgd_2, objvals_sgd_q8, '-g', LineWidth=2)\n",
      "<ipython-input-26-47e8d7a63a93>:16: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.xlabel('Epochs', FontSize=20)\n",
      "<ipython-input-26-47e8d7a63a93>:17: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.ylabel('Objective Value', FontSize=20)\n",
      "<ipython-input-26-47e8d7a63a93>:18: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.xticks(FontSize=16)\n",
      "<ipython-input-26-47e8d7a63a93>:19: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.yticks(FontSize=16)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABW4klEQVR4nO3dd3xUVfr48c8z6QkBElqQDgoIKB0sCEGsKCqiuIoKlrWs+oNV9GtBDIgoX9e67q4VQVFE+bIUWXWlBAVUBMWCAlIiSpESUoD0PL8/7iTMTCbJTEhI4Xm/XvOa3HPPPffcIcyTc+6554iqYowxxtQ0ruqugDHGGOOPBShjjDE1kgUoY4wxNZIFKGOMMTWSBShjjDE1kgUoY4wxNVK1BygRaSUic0UkXUQyRGSeiLQO4LgkEdFSXtk+eV0i8pCIpIhItoh8JyIjqu6qjDHGHCupzuegRCQa+A7IASYACkwBooHTVfVwGce2BFr6JMcAHwP/VtWRHnmfAMYDjwDrgD8BfwYuVdX/VNoFGWOMqTTVHaDGAs8CnVR1izutHfAL8ICqPhtkeTcAb+EEnsXutKbAb8BTqvqYR96lQBNVPb28chs3bqxt27YNpirGGGPKsG7duv2q2qSsPKHHqzKluAz4sig4AajqdhFZBVyOE7yCMRr4A/jEI+1CIByY5ZN3FjBdRNqp6vayCm3bti1r164NsirGGGNKIyK/lpenuu9BdQV+9JO+AegSTEHuLr/BwDuqmu9zjhxgi88hG9zvQZ3HGGPM8VHdASoeOOgnPRWIC7KsG3CuZ6afc6Rpyb7MVI/9JYjIbSKyVkTW7tu3L8iqGGOMOVbVHaDAGRjhSypQzo3At6r6vZ+ygj6Hqr6qqn1UtU+TJmV2kxpjjKkC1R2gDuK/BROH/5aVXyLSD+hMydYTuFtjIuIbkOI89htjjKlhqjtAbcC5R+SrC/BTEOWMBvKBd0s5RwTQwc85CPI8xhhjjpPqDlALgTNEpH1Rgoi0Bc527yuXiITjPNf0H1X1d7PoYyAXGOWTfj3wY3kj+Cpq0yb46itIToaPPoKMjKo4izHG1F3VPcz8NeBuYIGIFD2o+zjOc0uvFGUSkTbAVmCyqk72KeNSnG5Cf917qOpeEXkOeEhEMoFvgGuAc3GGsleJP/0J1q8/ur1uHfTqVVVnM8aYuqdaA5SqHhaRc4HngLdxBi4sBcap6iGPrAKE4L/FNxrnPtKHZZzqEeAQMBZIADYBI1V10TFfRClatNhCTs4BwsOzCA/P5siRvkCjqjqdMcbUOdXdgkJVdwBlzounqimUMupOVcttBalqAc4USlMqUMUKGTHiNtq1W168nZPzKXDe8Tq9MZUiJyeH1NRUMjMzKSgoqO7qmBoqJCSE2NhY4uPjiYiIqLRyqz1A1VWqUV7bOTlZ1VQTYyomJyeHHTt2EBcXR9u2bQkLC6PkYFhzolNV8vLyyMjIYMeOHbRu3brSglR1D5KoswoLvQNUXp4FKFO7pKamEhcXR+PGjQkPD7fgZPwSEcLDw2ncuDFxcXGkplbekzsWoKqMBShTu2VmZlK/fv3qroapRerXr09mZmallWcBqsp4B6j8/OxS8hlTMxUUFBAWFlbd1TC1SFhYWKXeq7QAVWW8A1RBgbWgTO1j3XomGJX9+2IBqoq4XL4tKAtQxhgTDAtQVcTlivTaLiy0AGWMMcGwAFVFQkK8W1AWoIwxJjgWoKqIb4BStQBljDHBsABVRUJDo3xSLEAZU9tt3ryZe++9l169ehEfH09YWBjx8fH079+f8ePHs27dOq/8SUlJiEjxy+VyUb9+fdq0acPQoUOZNm0aO3furLT6paWl8fTTTzNq1Ci6dOlCaGgoIsKSJUsq7RzHk80kUUV8A5SqDTM3prZSVSZPnszkyZMpLCykV69eXHPNNcTHx5OZmcn333/P3//+d5555hleeukl7rrrLq/jBw0aRGJiIgCHDx9m9+7drFq1io8++ojHHnuMpKQkHnzwwWOuZ0pKCg888AAALVu2pHHjxvzxxx/HXG51sQBVRcLCvAOUiLWgjKmtJk+eTFJSEq1atWL27NmcffbZJfLs3buX559/nvT09BL7EhMTSUpK8kpTVebNm8dtt93GQw89BHDMQapNmzYsWbKEnj17Eh8fz5gxY5g50+9CD7WCdfFVEd8A5XJZgDKmNtq2bRtTpkwhPDycjz76yG9wAmjatClTp04tbsGUR0QYMWIEc+fOBWDSpEns3r3bK09ubi6PP/44HTp0ICIignbt2jFhwgRycnIQkeJWWZG4uDiGDBlCfLy/hcprH2tBVZGIiHYsWnQbOTlR5OREER3dubqrZEylqG3P7qoe2/Fvvvkm+fn5XHfddXTt6m8BcG+hocF9rQ4ePJgBAwawcuVK5s2bV9w9qKqMHDmSBQsW0KFDB+6++25yc3OZPn06P/zwQ4WupbaxAFVFoqJO5dlni9dcpF+/aqyMMabCVq1aBcC5555bZedITExk5cqVrFmzpjhAzZ49mwULFnDGGWewfPlyIiOdZysnTZpE3759q6wuNYkFqCoS5TOIL8t6+Iyplfbs2QNAixYtSuxLSUlhxowZXmkNGzZk3LhxQZ2jqOx9+/YVp7355psATJ06tTg4AcTHx/Poo49y0003BXWO2sgCVBWxAGVM3aDuPkJ/88ylpKQwadIkr7Q2bdoEHaD8neObb77B5XIxYMCAEvl97z3VVTZIoopYgDJ1lWrteh2r5s2bA/h9XikxMRFVLV60r6J27doFQJMmTYrT0tPTi5+18pWQkFDhc9UmFqCqiAUoY+qGolF7S5curbJzLF++HID+/fsXpzVo0IDU1FS/ga+o27GuswBVRZwApYSHZxEbm0pU1K7qrpIxpgLGjBlDaGgoc+fO5eeff6708pctW8aqVauIiopi+PDhxem9evWisLCQlStXljgmOTm50utRE1mAqiIREQUsX+7ik0+iWbiwEW+91ZLCwkrobzDGHFcdOnRgwoQJ5ObmcvHFF7N69Wq/+dLS0oIqt+hB3auvvhpwRud5dt0VDYJ45JFHyM4+OhNNamoqU6ZMCfIqaicbJFFFQkNDyMsLIyzMaZ67XEpOTi5RURHVXDNjTLAmTpyIqvL4449z9tln07t3b/r160d8fDxpaWmkpKQUz3c3cODAEscnJycXzySRlZXFrl27WLVqFdu3byciIoJp06Zx//33ex1z7bXXMmfOHBYuXEi3bt24/PLLycvLY+7cufTt25etW7f6rev48ePZv38/QHHr6+mnn2bWrFkAXHHFFVxxxRWV8bFUuQoFKBHpDJwK1FPVtyu3SnVHbm5UcYACOHw4ywKUMbWQiJCUlMS1117Lyy+/zPLly3n33Xc5fPgwsbGxdOjQgTvvvJMbbriBXr16lTh+xYoVrFixAhEhJiaG+Ph4unbtyu23387111/vdwi7iPDBBx/w1FNPMWPGDF566SWaN2/OTTfdxMSJE72GnnuaO3cuv/76q1faf//73+Kf27ZtW2sClGgQw1xEpAfwOtCzKE1VQ9z7BgEfAdeo6qLKrWb16tOnj65duzbo4+bPT6Bhw6MTNXbosItWrZpXZtWMqTI///wzp556anVXw5RCRBg0aFCNux8V6O+NiKxT1T5l5Qn4HpSIdASSgU7ACzjByNNnQCpwVaBl1nV5ed5D+bJsKJ8xxgQsmEESjwHhQD9VvRf42nOnOk2xL4ATYw6OAOTnW4AyxpiKCiZADQHmqWpZ4yx3ACcdW5XqjoIC7z7i7GwLUMYYE6hgBkk0BH4vJ48Lp5VlgIIC7xZUTo4FKGNM5Qhm/EBtFUwLai9wcjl5ugK/Vbw6dUthoQUoY4ypqGAC1DJgmIh08rdTRPridAN+UhkVqwt8A1RurgUoY4wJVDAB6kkgH/hMRO7Efa9JRLq6txcBmcDfKr2WtZSqd4DKy7MAZYwxgQr4HpSqbhKREcBs4CV3sgDfu9/TgCtVdUdlV7L28g5Q+fkWoIwxJlBBzSShqh+LSDtgNHAG0AhIB74E3lTV1MqvYm1mAcoYYyoq6MliVTVNVV9Q1WtV9QJVvVpVn6locBKRViIyV0TSRSRDROaJSOsgjj9VRD4Qkf0ikiUim0RkrE+eFBFRP68rKlLnwOvmPczcApQxxgSuWieLFZFonMEXOTitMgWmAMtF5HRVPVzO8X3cxycDt+K05k4B6vnJ/gmQ5JO26RiqX67c3A5s2HAGOTlR5OZG0bBh26o8nTHG1CkBBygRKTlFbylU9bMAs/4ZaA90UtUt7vN8D/wC3A48W0Z9XMBMYKmqDvfYtbyUQ/ar6pcB1qtS7N9/DxMn3lO8/cgjx/PsxhhTuwXTgkrGaeEEIiTAfJcBXxYFJwBV3S4iq4DLKSNAAYlAF+COAM913NmqusYYU3HBBKjJ+A9QDXHm3zsLZ6j5N0GU2RVY4Cd9A3B1OccOcL9HisiXQG/gIPAe8D+q6hsOhonIEZzg+S3wlKrOD6KuQbMAZYwxFRfMMPOksvaLyBjg70AwHVnxOEHFVyoQV86xRXP+zcEZ9v4g0AcnkLYCPLv9FuFMbrsdaAbcDfxbRG5Q1VlB1Dcovsu1WIAypnYqKChg+vTpzJo1ix9++IHMzEzi4uJISEigX79+XHbZZVx22WUljlu+fDkzZszgiy++YPfu3eTk5BSvBXX++edz/fXX07JlS69jEhMTWbFiRfF2SEgIsbGxNGvWjNNPP52LL76Yq6++mnr1/N1qD97PP//Me++9x/r16/n222/57TdnMqC8vDxCQ6t3TdtKO7uqzhCR64CpOF13AR/qJ00COK5oBOIsVZ3o/jlZREKAp0Ski6r+5K7bPZ4Hisi/cYbGPwn4DVAichtwG0Dr1gEPKvTi24LyWLXZGFNLFBQUcOmll/Lxxx/TsGFDLrnkElq2bElqaipbt27l3XffZePGjV4BKiMjg9GjRzN//nzCwsIYOHAgQ4cOJSYmhn379rFmzRoeeughHnvsMb788kt69uxZ4ryjR4+mbdu2qCoZGRls376dJUuW8MEHH/Dwww/zxhtvMHTo0GO+vk8++YTJkycTEhLCKaecQmRkpNcS89VKVSvtBTwNpAWR/w/gFT/p/wT2lXPskzjBbZhPek93+nXlHP+AO1/z8urZu3dvrYh581Th6OvyyytUjDHV4qeffqruKtQIb7/9tgLavXt3TUtLK7H/8OHDumzZsuLt/Px8Pe+88xTQQYMG6Y4dO/yWu2HDBh0xYoQmJyd7pQ8aNEgBXb58eYljsrKydMqUKepyuTQ8PFxXrFhxbBenqhs3btQvv/xSjxw5oqqqbdq0UUDz8vIqVF6gvzfAWi3nuzfo56DK0YrgWmUbcO5D+eoC/BTAsVCyBVbU+ios5/iifFU2JXB09Be88cZpzJp1Mu+/35ILLxxZVacyxlSR1atXAzBmzBgaNGhQYn90dDSDBw8u3p41axZLlizhlFNOYfHixbRq1cpvuV26dGHu3LmcffbZAdclMjKSRx55hAkTJpCbm8vYsWNL5Pnjjz+45ZZbaNasGVFRUfTo0YOZM2eSnJxcvHS9p06dOtG/f3+ifLt8aoBKCVAiEiIit+KsphvM2ugLgTNEpL1HWW2Bs937yvIRzvNTF/mkX+h+L7UeIhKKMwhjh6ruCaK+QYmIyKV9+x9p0WIrTZrsJCqqyk5ljKkijRo1AmDz5s0B5X/99dcBuP/++4mJiSk3f0Xu84wfP56oqCjWr1/Phg0bitMPHDjAWWedxfTp0+nYsSPjxo2jR48e3HHHHTz33HNBn6e6BfMc1LYyymjmfs8FHg7i/K/hDFhYICITcFozj+Ms2fGKx7nbAFuByao6GUBVD4jIk8CjIpKB88BuH2AiMFOPPld1Lc6Q9f+4y20G3IUz6u/aIOoatIiISHJyjm6HhNgoCVNHSCC3iWuASlgz6corr2TatGm8/PLLZGZmMnz4cHr37k2bNm1K5M3Pz+err74C4Nxzzz3mc5cmNjaW3r17s3LlStasWUPXrk5H1EMPPcS2bdsYN26cV0C6++67OfPMM6usPlUlmNDtwn93WB7wA7AG+LuWveKuF1U9LCLnAs8Bb+N0uy0FxqnqIY+sgjM83LfFNxlnBvW/AOOB3Tj3wR73yLMdaOpOjweO4Izou0hVq3RpkMjIKAtQxtRyPXv2ZNasWYwdO5ZZs2Yxa5Yzrio+Pp6BAwdy8803M2zYMABSU1PJy8sDoEWLFiXKSk5OJjk52SutR48eXHHFFUHXq6j8ffv2Ac6ou3feeYfY2NgS3Xh9+vRh1KhRzJw5M+jzVKdghpm3rYoKqDP7+Yhy8qTgZ2Sf+0bbs5TxQK86s0dU3Z8yZYiMjCI9/eh2aKgFKFNHnACruXoaOXIkw4cPZ/ny5axcuZJvv/2WlStXMn/+fObPn8+NN97IjBkzyl3lNjk5mUmTJnmljR49ukIBquhc4m7Nbty4kSNHjnDOOef4vVeWmJhY6wJUZQ+SMB58bzqGhtaQoZvGmKCFhYVxwQUXMHnyZBYtWsT+/fuZM2cOMTExvPXWWyxYsIBGjRoRFhYGwK5du0qUkZSUVDxC7dNPPz2m+hSV36RJEwDS3X8NN2vWzG/+hISEYzpfdbAAVYV8A1RYmLWgjKkrQkJCGDlyJH/9618BWLZsGaGhofTv3x+ApUuXVtm5MzMzWbduHUDx+YpaTX/88YffY/bsqX2DtErt4hORiaXtK4eq6uPlZ6v7oqO9A1R4uAUoY+qa2NhY4GiX26233srKlSt55plnGDVqFNHR0ZV+zqeffpqsrCx69uzJqaeeCkDnzp2Jjo5m/fr1pKenl+jm8733VRuUdQ8qqYJlFo3EO+FFR3vPdRQRkU1hoeJy1ZIRUMYYZs+eTePGjRkyZAgul3en0549e3jttdcAGDjQWfDh+uuv5+2332bp0qUMGzaMmTNnlpjOCCAtLS3oumRnZ/Pss8/yxBNPEB4ezosvvli8LywsjFGjRvHaa6+RlJTkNYpv7dq1vPPOO0Gfr7qVFaAGl7HPBCAkxEVubgTh4UeH8mVlZRMTU/MeiDPG+PfVV1/xwgsvkJCQwIABA2jXrh0A27dvZ/HixWRlZXH55Zdz1VVXAU7X37x587jxxhtZsGAB7du3Z9CgQXTr1o3o6Gj27dvHhg0bWL16NeHh4cVddL5mzJhR3Oo5dOgQW7du5bPPPiM1NZXmzZszffp0BgwY4HXM1KlTWbp0Kc8//zxr165lwIAB7N69mzlz5jB06FAWLiz5eOn+/fsZP3681zbALbfcUjwA48EHH6Rz587H9kFWQKkBSlVXlLbPBC43N8orQB0+nGUBypha5L777uOUU05hyZIlfP/993zyySdkZ2fTqFEjEhMTue6667juuuuKv8wB6tevz/z581m6dCkzZ85k9erVrF69mry8POLi4ujatStPPPEEN954o9/WFVA84i4kJIR69eqRkJDAeeedVzxZrL+HgBs3bsyqVat4+OGHWbRoEWvXrqVTp07861//om3btn4D1KFDh/yO7nvrrbeKfx4zZkzNClCmcuTlRQFpxdtZNqW5MbVKq1atuOuuu7jrrruCPnbIkCEMGTIkqGOO9V5RQkIC06dPD7jcoglpayIbxVfFnAB1lAUoY4wJTFABSkSai8g/RGSLiGSJSIGfV35VVbY2ys+3AGWMMRURzFx8LXCmM2qGM5N4BPArzoSt7d1lrQfSSynihJSXV4+srGhyc6PIyYkiMrJmNqWNMaamCeYe1EQgAbhQVZeISCHwpqpOFpGWOBO/tgWC63Ct415//UtWrjy6vcKGnhhjqkFiYmKNvddUmmC6+C4EPlbVJb47VPV3nOUrooBJvvtPZL5LrFgPnzHGBCaYAJXA0UUCAQpwAhIA7tnHP8VZ2sK4WYAyxpiKCSZAZQDhHtsHAd/55NOBJsdaqbrEApQxxlRMMAHqV5wl3Yt8B5wrItEAIuICLgB+r7zq1X4WoIwxpmKCCVBLgcEiEubengmcBKwWkaeBVUBXYE7lVrF2swBljDEVE8wovjdwuvUaA7tVdZaI9AbuAU5353kPeKJyq1i7tW//Po88soDw8CwiIrKIjBwDXFPd1TLGmBqvzAAlIvOAV1X1Y1X9BZjmuV9V/yoiU3Geg0pRVf8LkZzAGjX6jj593i3eTkk5qxprY4wxtUd5XXxXAItFJEVEJrgf1vWiqvtU9SsLTv65XN59fIWF1sdnjDGBKC9A3QB8hjM4YhKQIiILROQS8Zy615TKN0CpWoAyxphAlBmgVPUdVR0MdASeBvYBw4CFwA4RSRKRVmWVcaILDbUAZYwxFRHQKD5V3aqqD+K0pEYAnwDNcaY/2iYiH4rI5e6h5saDb4CC7GqphzHm2G3evJl7772XXr16ER8fT1hYGPHx8fTv35/x48ezbt06r/xJSUmISPHL5XJRv3592rRpw9ChQ5k2bRo7d+6s1DpmZGQwdepUevToQVxcHA0aNOC0007j0UcfZd++fZV6rqoW1HpQqloA/Bv4t3v+vVuAm4ChwMXAHhGZrqqPVnpNa6mwMN8AZS0oY2obVWXy5MlMnjyZwsJCevXqxTXXXEN8fDyZmZl8//33/P3vf+eZZ57hpZdeKrF21KBBg0hMTATg8OHD7N69m1WrVvHRRx/x2GOPkZSUxIMPPnjM9UxPT6dfv35s3ryZPn36MGbMGAA+++wzpkyZwowZM1i7di3NmjU75nMdDxVesNA9/94kEZmM84Duo8BZwMPunw0QFhbptS1iAcqY2mby5MkkJSXRqlUrZs+ezdlnn10iz969e3n++edJTy+5oENiYiJJSUleaarKvHnzuO2223jooYcAjjlIvfrqq2zevJmbbrqpxKKFY8aMYebMmbzyyitMnDjxmM5zvBxTl5yIhODMvXcP0N+dXHislapLwsO9W1AWoIypXbZt28aUKVMIDw/no48+8hucAJo2bcrUqVN54IEHAipXRBgxYgRz584FYNKkSezevdsrT25uLo8//jgdOnQgIiKCdu3aMWHCBHJychCR4laZZ10Bhg0bVuJ8l112GUCt6uarUAtKRDoAtwKjcdaHEpwpjqYDr1da7eqAiIgoCj1CdkiIBShTNyQnV2wgb716vejTZ53ffWvX9ubQoW8qVG5iYtUsJfHmm2+Sn5/PddddR9euXcvNHxoa3Nfq4MGDGTBgACtXrmTevHnF3YOqysiRI1mwYAEdOnTg7rvvJjc3l+nTp/PDDz/4LauofosXL2b48OFe+z788EMAzjvvvKDqV52CWbAwHGeAxJ+BQThBqQD4EHgV+EhVrfXkIyIiymt6I5fLApQxtcmqVasAOPfcc6vsHImJiaxcuZI1a9YUB6jZs2ezYMECzjjjDJYvX05kpHO7YNKkSfTt29dvObfeeiuzZ8/mjTfe4IcffmDAgAGoKp9//jk//fQTTzzxBJdfXnsWnCg3QIlIN5zW0vVAHE5g+hWntfSGqu6q0hrWcpGR3gEqNNQClDG1yZ49ewBo0aLEPAWkpKQwY8YMr7SGDRsybty4oM5RVLZn99ubb74JwNSpU4uDE0B8fDyPPvooN910U4lyIiMjWbZsGWPHjuWVV15hzZo1xfuuuuoqrrjiiqDqVd3Km+roC6AfTlDKBxbgtJY+0dq2NGM1iYz0vgcVGmrDzI2pTYq+6vzNTZCSksKkSd5rtLZp0yboAOXvHN988w0ul4sBAwaUyO9776nIgQMHGDFiBBs3buS9997j/PPPR1VZsmQJY8eOpX///ixdupR+/foFVb/qUl4Lqj+wHee+0nSbzih4UVG+AcpaUKZuqIp7PqXdm6pOzZs3Z+PGjX6fV/JcRj0/P5+wsLASeQKxa5fTEdWkydHl9NLT04uftfKVkJDgt5z77ruPFStWsGDBguJBEQDXXHMNkZGRXHHFFTzwwAMkJydXqJ7HW3mj+C5U1Q6q+qQFp4rxDVDh4RagjKlNikbtLV26tMrOsXz5cgD69+9fnNagQQNSU1PJy8srkb+o29FX0UCIwYMHl9hXlOb7MHFNVt5UR58er4rUVfXq1eemm37kuuu2MmLELm64IaW6q2SMCcKYMWMIDQ1l7ty5/Pzzz5Ve/rJly1i1ahVRUVFeI+969epFYWEhK1euLHFMaS2gnJwcwP9Q8qK08PDwEvtqKpuaqIpFRobw669d2b27PampzTl4sCEFBdVdK2NMoDp06MCECRPIzc3l4osvZvXq1X7zpaWlBVVu0YO6V199NeCMzvPsuisaBPHII4+QnX303nVqaipTpkzxW+Y555xTXFahx/MtBQUFPPbYYwAMGTIkqHpWpwrPJGECIwKRkd4r6WZnQ0xM9dXJGBOciRMnoqo8/vjjnH322fTu3Zt+/foRHx9PWloaKSkpLFmyBICBAweWOD45Obl4JomsrCx27drFqlWr2L59OxEREUybNo3777/f65hrr72WOXPmsHDhQrp168bll19OXl4ec+fOpW/fvmzdurXEeaZNm8bq1at56623WLduXfHQ+KVLl/LTTz/RuHFjpk6dWsmfThVS1Wp94UxAOxdIBzKAeUDrII4/FfgA2I8z0d0mYKxPHhfwEJCCM1vrd8CIQM/Ru3dvPRbx8apw9LVv3zEVZ8xx8dNPP1V3FWqcjRs36rhx47R79+7aoEEDDQ0N1bi4OO3Tp4+OGzdO161b55X/scceU6D4JSJar149bd26tV588cX61FNP6e+//17q+XJycnTSpEnarl07DQ8P1zZt2ujDDz+s2dnZCuigQYNKHLNt2za9/fbbtX379hoeHq4RERF68skn6913313muSpLoL83wFot57tXtBpHi4tItDtY5AAT3P+IU4Bo4HRVPVzO8X2AZUAyznNZ6cApQD1VfdYj3xPAeOARYB3wJ5wHji9V1f+UV88+ffro2rVrg728Yi1bgucAoB07oJUtUmJquJ9//plTTz21uqthSiEiDBo0qMaNyAv090ZE1qlqn7LyVHcX359xlovvpKpbAETke+AX4Hbg2dIOdC/tMRNYqqqec3os98nXFCc4PaWqfyvKIyInA08B5QaoY+UzkM+ru88YY4x/1R2gLgO+LApOAKq6XURW4UxCW2qAAhKBLsAd5ZzjQiAcmOWTPguYLiLtVHV7sBUPxoAB79K37w4iIrKIiMjiyJGxQMmn0o0xxhwVdIASkWHAKJx7PzGqerI7/VSc1XbfUdVAV+DqijM7ha8NwNXlHFv0eHWkiHwJ9AYOAu8B/6NHl67titOFuMXn+A3u9y44DyNXmcGDn6d166+Lt7OyRmAByhhjyhbMZLECzMCZkw+cAQmenVcHgak40yJNC7DYePdxvlJx5v0ry0nu9znAS8CDQB9gMs7Ai6Juv3ggTUvebEv12F+CiNwG3AbQunXrcqpStsJC7z6+nBzr4zPGHJvqHD9wvATzHNRfgBuAN3G+1P/muVNV9wCrgEuCrIO/TzmQefyL6j5LVSeqarL7HtMk4AoR6eJRVtDnUNVXVbWPqvbxnH6kIixAGWNM8IIJULfgjLj7s6qm4/9L/xegXRBlHsR/CyYO/y0rTwfc776zXfzX/d7D/Z4KxEnJmR7jPPZXKd8AlZtrAcoYY8oTTIDqBCz301XmaS8QTHNjA849Il9dgJ8COBZKBsqiQFTokS8C6ODnHARwnkrgHaDy8ixAGWNMeYIJUPlAZDl5WgCHgihzIXCGiLQvShCRtsDZ7n1l+Qhn8MNFPukXut+LHlz6GMjFGdjh6Xrgx6oeweeo57WVk5NR9ac0xphaLphRfD8BiSIi/lpRIhIJnAt8G0SZrwF3AwtEpOhB3ceB34BXPMpuA2wFJqvqZABVPSAiTwKPikgGzgO7fYCJwMyioeuquldEngMeEpFM4BvgGnddj8vSki5XY6/tnJz9x+O0xhhTqwUToN7GGS33nIjc67lDREJwnlk6CWc0XUBU9bCInAs85y5fgKXAOFX1bIkJEELJFt9kIBNnAMd4YDfwNE6Q8/QITstuLJCAMx3SSFVdFGhdj0V4uHevZ35+yZmGjTHGeAsmQL2C82Dt/8N5RikTQETmAmfgBKcFqvpOMBVQ1R3AiHLypOBn1J27JfcsZT/Qi6oW4Eyh5H8K4CoWFdXYJ8UClDHGlCfge1DuL/lLcVot4UBHnKBxJc7ceY9T/sO1J6TYWO8WlMtlXXzGGFOeoGaSUNV8IElEJuEEqEY4E7RudAcw40eDBo295t+LiLAWlDHGlKdCc/G5u9Y2VXJd6qxGjZrw++9Ht6OiLEAZY0x5Au7iE5GvROROESlvCiLjo1kz73tQ9ertp7Cw7k9TYkxdUVBQwGuvvcagQYOIj48nLCyMpk2bcvrpp3PrrbeycKH/p2KWL1/O6NGj6dixI7GxsYSHh5OQkMCQIUN46qmn+N3zL1e3xMRERKT4FRoaSlxcHJ07d2bkyJG8+eabHDoUzNM85du+fTt33HEHnTt3Jjo6mmbNmnHmmWfy6quvkpubW6nnCkbA60GJSFEXXh6wCGdevo9PhK69Y10PCuDjj6OJjDzaz9e9ezpxcfWPtWrGVBlbD8pRUFDApZdeyscff0zDhg255JJLaNmyJampqWzdupUvvviCXr16sXLlyuJjMjIyGD16NPPnzycsLIyBAwfSrVs3YmJi2LdvH2vWrOG7774jPDycL7/8kp49exYfm5iYyIoVKxg9ejRt27ZFVcnIyGD79u189tlnHDx4kISEBN544w2GDh16zNf39ddfM3jwYLKysrjooovo1q0bGRkZLFq0iJ07d3LBBRfw8ccfU3IyHv8qcz2oYFa+bQ48gDMzQyFQAOwBngG6B1pObXwd64q6qqrXXjtTBw78QLt3T9a2bX/ULVvyjrlMY6qSrajrePvttxXQ7t27a1paWon9hw8f1mXLlhVv5+fn63nnnVe84u2OHTv8lrthwwYdMWKEJicne6UPGjRIAV2+fHmJY7KysnTKlCnqcrk0PDxcV6xYcWwXp6pDhw5VQGfMmOGVfujQIe3SpYsCQZ2nMlfUrdAXNs7SFn/HGS9dFKy+xXnOqElFyqzJr8oIUL16qdey719+ecxFGlOlLEA57rzzTgX0ueeeCyj/jBkzFNBTTjlFDx06VG7+vDzvP1bLClBFJk6cqID26NGjxL49e/bozTffrE2bNtXIyEjt3r27zpgxQ5cvX66APvbYY175O3furICmpqaWKOuee+5RQOfOnVvudRSpzAAVzFRHnq2udap6j7tVNQKny68LzvNIv1WkzLrOd0L0fTZOwphaoVGjRgBs3rw5oPyvv/46APfffz8xMTHl5g8NDX6s2vjx44mKimL9+vVs2LChOP3AgQOcddZZTJ8+nY4dOzJu3Dh69OjBHXfcwXPPPee3rK5dnelQFy9e7JV+5MgRli1bRkxMDGeeeWbQdawMx7SirjrDzv8tIkuAu3CWugirjIrVNb4Bar89CmVqMZkU2P2I6qaPHftgpCuvvJJp06bx8ssvk5mZyfDhw+nduzdt2rQpkTc/P5+vvvoKgHPPPfeYz12a2NhYevfuzcqVK1mzZk1xkHnooYfYtm0b48aN8wpId999d6lBZsqUKaxevZoxY8bw/vvv06VLFzIyMvjwww/Jz8/ngw8+4KSTTvJ7bFWrcIByL19xATAaZ067SJy59JZWTtXqlsY+k0lYC8qY2qFnz57MmjWLsWPHMmvWLGbNmgVAfHw8AwcO5Oabb2bYsGEApKamkpeXB0CLFiVXzU5OTiY5OdkrrUePHlxxxRVB16uo/H3uL5O8vDzeeecdYmNjSUpK8srbp08fRo0axcyZM0uU07lzZ77++muuvfZaFi1axKJFzgxwYWFhjBs3jjPOOCPoulWWiiz53gUnKF2PM6+d4KwDNRN4S1VLjps01sVn6pTKaJnUJiNHjmT48OEsX76clStX8u2337Jy5Urmz5/P/PnzufHGG5kxY0bRPfpSJScnM2nSJK+00aNHVyhAFZ2raHTdxo0bOXLkCOeccw4NGjQokT8xMdFvgPr222+54ooraNq0KZ9//jk9evQgLS2NWbNmMWHCBObPn8/XX3/tt8yqFsxzUHeLyNfAD8D9ONMbvQ4MUNVOqjrVglPpmjU7QI8eyxk06AMuv/yfREUtqO4qGWOCEBYWxgUXXMDkyZNZtGgR+/fvZ86cOcTExPDWW2+xYMECGjVqRFiYc5dj165dJcpISkoqHgDw6ae+a60Gp6j8ohW/09PTAWjWrJnf/AkJCSXS8vPzGTlyJPv27WPRokUMGDCAevXq0bJlSx588EHuuecefvnll1LvX1W1YAZJvAj0xFnBdhTQXFVvV9XVVVKzOqZZs8947rlzSUoaybhxd9G69evVXSVjzDEICQlh5MiR/PWvfwVg2bJlhIaG0r9/fwCWLq26ux2ZmZmsW7cOoPh8RS2cP/74w+8xe/bsKZG2ceNGtmzZwqmnnuo3gA0ePBig+FzHWzAB6mGgtapepKqzVTW7qipVFzVo4N3HFxZmfXzG1AWxsbHA0S63W2+9FYBnnnmGI0eOVMk5n376abKysujZs2fxQ7FFs0CsX7++uDXlyffeF0BOTg4A+0sZtVV0fys8PLySah6cYGYzf0pVS7ZZTUDi4rxHSURGWoAypjaYPXs2n376KYWFhSX27dmzh9deew2AgQMHAnD99dczZMgQNm3axLBhw/xOZwSQlpYWdF2ys7OZOnUqTzzxBOHh4bz44ovF+8LCwhg1ahSZmZklBkmsXbuWd94puRJSt27daNiwITt27CgeHu9Zv7/97W8ADBkyJOi6VoZjGmZuAtekSROvoeUxMTbO3Jja4KuvvuKFF14gISGBAQMG0K5dO8CZv27x4sVkZWVx+eWXc9VVVwFO19+8efO48cYbWbBgAe3bt2fQoEF069aN6Oho9u3bx4YNG1i9ejXh4eHFXXS+ZsyYUdzqOXToEFu3buWzzz4jNTWV5s2bM336dAYMGOB1zNSpU1m6dCnPP/88a9euZcCAAezevZs5c+YwdOjQEnMGRkRE8Pzzz3PTTTfx5z//mffee4+ePXty8OBBFi5cyL59+zjjjDO45ZZbKvlTDUypAUpEtuEMGz9PVbe7twOhqtqhUmpXhzRuHEdBgYuQEOevsJiYDLKzc4iMjKjmmhljynLfffdxyimnsGTJEr7//ns++eQTsrOzadSoEYmJiVx33XVcd911XnPV1a9fn/nz57N06VJmzpzJ6tWrWb16NXl5ecTFxdG1a1eeeOIJbrzxRlq2bOn3vEUj7kJCQqhXrx4JCQmcd955XHzxxVx99dV+HwJu3Lgxq1at4uGHH2bRokWsXbuWTp068a9//Yu2bdv6ndR29OjRtGvXjueff54vvviCFStWEBERQadOnbj33nsZN24cERHV8z1VVgvKhROgStsuTe14gu84CwlxcehQIxo0ONq1t3fvAVq3rp4H4IwxgWnVqhV33XUXd911V9DHDhkyJOjuMX/3ioKRkJDA9OnTgyp34MCBxV2UNUmpAUpV25a1bYJ35EgTrwC1b98+C1DGGFOKCs3FZyomJ8d7oERamg2UMMaY0gTzoO4yEbmxnDzXi8iyY69W3ZSf7z3UPDPTBkoYY0xpghnFlwgkl5OnDTCoopWp+7wD1JEj1oIyxhwfiYmJ5U7FVNNUdhdfFJBfyWXWGSEh3l18ubkWoIwxpjTBPgflN/y6ZzZvDQzF1oMqVXi4dwsqP9+6+IwxpjRltqBEpFBECkSkwJ2UVLTt+cJpNW0DegDvVW2Va6/oaJ8pzbEWlKnZaluXkKlelf37Ul4L6jOOtpoGAjuAFD/5CoADOGtB2SyopYiN9e7iCwmxFpSpuUJCQsjLy6u2edhM7ZOXl0dISEillVdmgFLVxKKfRaQQeFNVJ1fa2U8w8fGd+Mc/HiE9vQnp6Y2JjGzHTTdVd62M8S82NpaMjAwa+662aUwpMjIyiifPrQzB3INqB6RV2plPQE2btmb69CnF26Us22JMjRAfH8+OHTsAZ+qesLAwr+l8jAGnWy8vL4+MjAwOHjxI69atK63sYALUXqCJiGSpaq7vThGJAJoBe20pDv98V9Xdvx8KC8Flj0ubGigiIoLWrVuTmppKSkoKBQUF5R9kTkghISHExsbSunXrSp23L5gANREYB7QAUv3sjwE2An9z5zU+IiIgNhYyM53tggJIT4e4uOqtlzGliYiIoHnz5jRv3ry6q2JOQMH87X4xsERV/QUn3OlLgEsro2J1lW93/j4byGeMMX4FE6DaApvLybPZnc+UwrebzwKUMcb4F0wXXxhQcklJbwpEVrw6dd9JJ2XQsuUeGjTYT8OG+zhwoDsW040xpqRgAtQ2yp9nLxH4NZgKiEgr4DngfJy1pJYA41R1RwDHlvZUWE9VXe+RLwVnnkBfw1V1fjD1PVZDh45l7NgZxdt7974G3Ho8q2CMMbVCMAFqIfCgiDygqv/ru1NEHgR6ASX2lUZEooFlQA4wGqcFNgVYLiKnq+rhAIqZAbzik+avK/ITIMknbVOgda0sLpf3TaisLOvjM8YYf4IJUH8DRgFPishI4L/ATpxRfRfiTHO0gyACFPBnoD3QSVW3AIjI98AvwO3AswGUsVNVvwwg3/4A81Wp8PAEr+28vHIbisYYc0IKOECp6kERSQTeAc7EaS0pR5d4Xw1cr6oHgzj/ZcCXRcHJfZ7tIrIKuJzAAlSt0qjRKV7bISHljTsxxpgTU1CPiKpqiqqeDfQB7gYedb/3UdUBqpoS5Pm7Aj/6Sd8AdAmwjDtFJEdEjrgXVTynlHzD3HlyRORLEbkiyLpWitatO3pt169vAcoYY/wJdrkNAFT1G+CbSjh/POCvxZUKBPL46izgQ2AXziCI+4FlInK+qiZ75FsEfA1sx5nt4m7g3yJyg6rO8lewiNwG3AZU6tQdJ5/cnj/+cBES4gyIbNTodzIyDlO/fkylncMYY+qCCk2yIyIxItKzjNZKMPyNxAtowi9VvUFV56jq5+5AMwAnWE3xyXePqr7lzjcXGAKsBZ4so+xXVbWPqvZp4vvw0jGIjAznwIF2Xmm//LKllNzGGHPiCipAiUhLEfk/nFbPWmC5x74BIvKT+z5VoA7itKJ8xeG/ZVUmVc0EFgN9y8lXAHwAtBSRKpvDJSk5iUvevYRf07xH3mdmenfz/f67dfMZY4yvgAOU+4v8K5zBCx8CX+Dd0vkKaApcE8T5N+Dch/LVBfgpiHI8CaWs/OsnHwHmrZDklGT+88t/+CX1F5893gEqLc0ClDHG+AqmBfUYTgA6T1WvBD713KmqecDnwNlBlLkQOENE2hcliEhbdxkLgyin6Nj6wCU4wbKsfKHA1cAOVd0T7HkC1bZhWwBS0lK80qOjvQNUXp4FKGOM8RXMIImhwEKfwQe+dgDB3Jd6DWfAwgIRmYDTmnkc+A2Ph29FpA2wFZhctGCiiIwHOuF0MxYNkhgPJOA8r1V07LU4rb7/uMttBtwF9AauDaKuQWvTwJm8wreLr2lT7wAVHm4ByhhjfAUToJrhPEBbljycZTcCoqqHReRcnKmO3sbpdluKM9XRIY+sAoTg3eLbBAx3vxoAGcAq4BZVXeORbztOy+9pnPtdR3BG9F2kqp8EWteKKG5Bpad4pbdr15EdHs/nxsVtQlVtMThjjPEQTIBKBVqVk6cjEFSXmXvOvRHl5EnBZ2Sfqi7CGT5eXvlfAucGU6fK0qah/xZUmzYt+eWXSCIinHUdY2MPsnfvAZo1s6W1jTGmSDD3oFYBl4lIgr+dInIKcBEeI/tOdKXdgwoJcbF/v/eMElu2WDefMcZ4CqYF9TTOvZwVIjIOiAbnmShgIE43XSHwTCXXsdZqWb8lLnGxM3MneQV5hIWEFe/77beRfPXVIH7/vSO//96Ru+/uytnBDC8xxpg6Lpi5+L5yz67wMs4w8yIZ7vd84GZV3VCJ9avVwkPCOSn2JH7P+J3fM36nXdzRB3QzMibw978fzbvpuM+rbowxNVuwc/G9CXQDXgTW4Iys+wb4J3C6qr5T6TWs5Urr5uvoPZCPzdbDZ4wxXoKei09VfwH+WgV1qZPaxLRgJfBruvdACQtQxhhTtgpNFmsCUFAAt95K2z3/hjPKb0H98gsUFoKrQrMjGmNM3VNqgBKRoim8d6pqgcd2IHKAfapaeEy1q81CQuDAAdrszQVKBqhGjSAuDg66ZxzMyoKdO6FVeQP5jTHmBFFWCyoFZ2aHU3GWUC/aDlSOiMwH7lDVjPIy10l//Sttb3Ue1fr14HavXSLQqVMhW7bsolWrzbRsuZnNmwfTqlWn6qipMcbUOGUFqLdwAlK6z3YgInGmIfoTcAj3ukonnMRE2iZ0BjaSsrPk3Lc33XQrHTu+Wby9e/c/cT42Y4wxpQYoVR1T1nYg3EtzXBx0reoKEVrdei/suI3f8vaTX5BHqMezUBER7b2yHzliY82NMaZIVd+S/wxnfr4TVuR1N9L8sIsCF+z6ZK7XvoYNvVtLISHrjmfVjDGmRqvoirqtROQyEbnB/e731r6qvqCq7f3tO2FERNAm5iQAUt7+u9eu008/w2v7pJPWcORI9nGrmjHG1GTBrqh7ioh8ijNg4t/ADPd7ioh8KiIdyzj8hNX2ZGeB319/+gIWLy5Ob9euFfv3tyneDg/PZe3ar497/YwxpiYKZkXdk4HVwBBgG86gif91v29zp6905zMe2jZzuvJSGgKXXgqXXAI//wxAWpr38lnbt39+nGtnjDE1UzAtqCeBRsBYoJOq3qSqD6nqTThDz/4KNAamVn41a7eiZTdSzu8DsbHwn//AaafBwoXExnoHqIICC1DGGAPBBaghwH9U9e++D+CqaqGqvgB8BJxXmRWsC4rm4/u1dQPYsgVuuMGZaWLiRLqcOsArb0LCKvLzC6qhlsYYU7MEE6DCgfXl5FkPhJWT54RTtPR7SloKNG0Kr73mvH/3HV1T95GRcXShwujoTNav/66aamqMMTVHMAHqO6C8+0snA99XvDp1U1EX3470HRRqIUREwO23A7D2jUk89JPwxYGj+Tdtsm4+Y4wJJkBNBa4UEb8P3orIJcBw4InKqFhdEh0WTdOYpuQV5rE7c7eTeMcdzOjlYmDb5fyUs485vx3Nn5VlAcoYY8qaLPZGP8kfAR+KyFKch3D/AJoBg4BzgUU4AyWMjzYN2rD38F4WbFrAyfEns2jTIl667OitvE2ZUKAQItC48ecUFioul1RjjY0xpnqJqv/p9USkkJJz7wXyjamqGnKsFatJ+vTpo2vXrj2mMkZ+MJIPfvrAKy1MQvnHgnymDXSxtWEhr/SCjrHOvqZNN9Gliz1WZoypm0Rknar2KStPWZPF3lTJ9Tmh3dPvHvYd2YeqEhYSRoOIBtx35n2cuXgcn/26hq0N4acMJ0DlZkXy3XebLUAZY05oZU0WO/N4VqSuO6fNOSwfvbzkjnvv5cxn/sSs7rBjLfR6ArZvPpl3Rl3Ktdce/3oaY0xNYeu3VreRIznj0VcAWFLQlJifXXQt+Jkli7N4ZtXzvPP9O9VcQWOMqR5BLfkuIoOAs4GTcO5P7QZWqeqKKqjbiUGE0y+5majvx5HZaC9fRXfgrCNbqRfxf4xf8lfCXGFc1ukyYiNiq7umxhhzXAUUoNyB6V8cXU2vaLCEuvdvBP5igapiQl2h9G3Rl89+/YwFLRM4a/NWtNcbAOQV5rE8ZTmXbRbYtw9uvrmaa2uMMcdHuV18IjIC+BTojNNimg1Mw5kodrY77VTgUxG5suqqWred2fJMAFa2DOVwGOw4bXXxvo83LYY//QluuQU2bKiuKhpjzHFVZoASkZOAmUA+cCfQRlWvd08S+6CqXg+0Bm7HWZjwLfcxJkhFAWpb+1Q+6Ao5EbnIYeeRso82LkKPHHEyzplTXVU0xpjjqrwW1DggGhilqq+oaolZTN0Txb4GjHLnHVvptTwBnNHSWbwwtcVWXjrXSftr9wPUc4WRkrWbzY3cGd9/H0p5ds0YY+qS8gLURcBXqvrv8gpS1fnAV4DfqZBM2ZrVa0a7hu3IlSOsqw9RIXBegtKvUR4AHxfNgrhpE2NnjeLkF0/mlwO/VF+FjTGmipUXoNrgLFIYqNVA2wrX5gRX1IoCOLepE6T6u1tOH50CXHABK1vDi9tms/XgVq764CqO5B2pnsoaY0wVKy9AhQG5QZSXB9SpaY6Op6L7UACXJDjvfeOc9xVt4fD9Yxl7kbMd5grj+z++5y+L/0Jp01UZY0xtVl6A2g2cFkR5XYE9Fa/OiW1wu8EIwmmuFnSOcdLiwqFjPcgOhZsPzuCbk6BlOnx+5mtEhUYx87uZvP7N69VbcWOMqQLlBajPgPNFpHN5BYnIqcCF7mMCJiKtRGSuiKSLSIaIzBOR1gEeq6W8evjkc4nIQyKSIiLZIvKde/h8jdKtaTdW3byKTwa+QhOPjtV+8c77++7JZv/3U+j/3w28cqkzA8XdH93ND3/8cLyra4wxVaq8APUSTjffhyLSpbRM7uC0CKd77x+BnlxEooFlOM9YjQZuAE4BlotITIDFzADO9Hlt9snzOJCEcz0XA18CH4jI0EDreryc2epMmvdJpI3HTIhFAQrgrAbd+NOPwPvvc0PHq7i1563kFuQy/tPxx72uxhhTlcoMUKq6DngaaA98IyLvisgtInKBiJzv/nk28K07z7OqGsy6FH92H3eFqs5X1QXAZTiDM24PsIydqvqlz6t45ICINAXGA0+p6t9Udbmq3g4sB54Koq7HT0wMsa5TaOyel6NLfWgY5kzf8eyVryEtWsCvv0KTJjw1ey8NXNH8d+t/+e/W/1ZrtY0xpjKVO5OEqv4PTuvDBfwJeBVn4cKP3T9fg9Nyehx4IMjzXwZ8qapbPM63HVgFXB5kWaW5EAgHZvmkzwJOE5F2lXSeynX66bR1t6JCBP52OjzfHfZ+twveeQd694bDh2n03kIe+sSJxw98+oCzpLwxxtQBAc1mrqqTcbreHsdpeWwENgHJ7rSOqvqYBj+crCvwo5/0DUCpXYo+7hSRHBE5IiLLROQcP+fIAbb4pBfNGRToeY6v7t2ptx2auFfo6FAPTm8Ihw5NIKvfGbB2LaSkwLRp/L91IbRMh+/++I5Z3/vGYWOMqZ0CXm5DVX91B6HzVLWrqnZR1SHutO0VPH88cNBPeioQF8Dxs4C/AOcBtwGNgGUikuhzjjQ/wTPVY38JInKbiKwVkbX79u0LoCqV7PTTAWg7E7Tw6ELGzZv/zLvvPuZstGkDDzxA1CvTmbLMSZqw+D6y8rKc2SbS0iA//zhX3BhjKkdNWA/KX6srkKXlUdUbVHWOqn6uqrOAAcAuYIpPWUGfQ1VfVdU+qtqnSZMmgVSncnXvDkDMzlC2bxnltatdu/9lxYrPjybceCPXXzWZ7nvgt7z9XH1HPPsbhkNcHISHQ5MmcNppMGMGAClpKRzM8vd3gTHG1BzVHaAO4r8FE4f/llWZVDUTWAz09UhOBeJExDcgxXnsr3natoUnn4R//Ythw1/kwIGWxbtUXbz11vdkZBzNHvLIBF4OH07DLFjcOpvut+az7NRIAAoO7OeP7T/yrxl30/+1frR7oR19X+trs1AYY2q0oBYsrAIbcO4R+eoC/FTBMn1bTBuACKAD3vehiu49VfQ8Ve/BBwFoAjRsOAM4jx07OvLkk2+zcWM/8vJg5kwQAUQ444V5rF+fzKjV41nFOs67JofI0Eiy8rPcBR6GXV8DsPXgVv62+m9MPGeCs8tV3X+rGGOMt+r+VloInCEi7YsSRKQtzqq9C4MtTETqA5fgTFpb5GOc6ZpG+WS/HvjxGO6fHVdDhgxhzZq53Hbbt2zc2A+At9+GpCTvfG16JJJ8x5dMHDiREFdIcXCqRzjnbYV3fu/PR6M+AmDaqmn8Pri30xV4113w3XfH85KMMaZsqlptLyAGp1XzA86w8suA74BtQD2PfG1w1qSa6JE2HngNuA5IxHnQ9wecYHSOz3meArKBe915/wUUAsMCqWfv3r21JjhyRLVLF1VnBMTR13PP+c9/OPewZuZkakFhgeqOHaoiqhERqmlpOmLOCCUJHXWlT2H9+6vOnauan39cr80Yc2IB1mo5372i1TzRqHtao+eA83G655YC41Q1xSNPW2A7MElVk9xpw4AHcZahbwBk4Dw/NUVV1/icIwR4COfB4AScIfKTVXVuIHXs06ePrl0bzPPHVWfDBhgwwBmg52n69AJuuqmceXrPPReWL4fXX2fbJWdx6j+7kBsCy0Jv4cDBXby/ewkbG+QRmwMNQ2Jo1bEPD9z0Ou0bnVx2ucYYEyQRWaeqfcrMU90BqjaoSQEK4Isv4LzzoGiR3fr1D/Dkk5cQHT2UG26YQEhIKT2306c7y8YnJsKwYTz0n/t4yvepMR9RBS4mnz2Bcec/Sqirum9ZGmPqCgtQlaSmBSiATz+FSy+F2NhdPP30BbRr5zx3vGXLlVx99UwaNKhX8qD0dEhIgOxsaNiQzCNpdEtqwo7cffQ9qS/XdL2GQW0HcSQrg/RPP2T25/9kdsccAHrVO4V/XPOW15pVxhhTURagKklNDFAA8+blcPjw6bRq5T037u7dXWjT5g3OOstPMLnmGmfZeICzz+bgfxdyOP8ILeu3LJl3507+c89F3NnmR3Y0dJKu7XINT54/jTYN2wBQqIW4pLrH2hhjahsLUJWkpgYogOTkZDIyrqZ+/f1e6YWFwrZtd3DllU8SH9/g6I4PP4Rhw5yfV6yAgQPLPkF+PocmPcKTX/wvz5wJOaHOYon1I+pzKPcQOQU59EjowZjWl3PdrniadO4NZ59dyVdpjKlrLEBVkpocoAB++SWFNWuuoEWLksPE09ObkJ4+nssuu5OGDWMhLw+uvRZat4Znnw38JJ99xq93XMvDp+7i3dP9ZwktgOEb4d4GF3HGU7OgUaMKXpExpq6zAFVJanqAAsjIOMz779/NySfP8Ls/MzOeAwf+H4MH30qbNi0qdpK0NLj7blLnvUOhQL1cEIVFnWBG7xA+al9A0bSBZ+4O5f/1vIMrbv5fIsOiiovIyc8hMzeTxtGNK1YHY0ydYAGqktSGAFVk2bJl7Nt3B82a/eJ3f0GBi5SUi4iPf4jzzx9APT9jKcq1aZOzHtW+fXDgAHTuDIMGsTNnPy99MpmXv5tOWpgzSW3DvFCu6TicUzuexZI1c1i2/2uOhBQwjI5MuPIF+p120TFcrTGmtrIAVUlqU4ACOHIkm/fff4qmTZ8hOvqQ3zxPPTWD5OTRDBni3JIaPBg6dnRPm3SMDmVnMPPlO5n+yxy+aVpQYn9YAeS5H9kanJVAn0bdaNnsFE5q3ZX41p2pH9mAhpENad2gNeEh4cdeIWNMjWMBqpLUtgBVZO/eVBYvfoGmTV8gJia9OL2gwMWIEXtIT/eepb1ZM7j++sWcfvpPtGjRi9NO60nTpn5XIwnMwYP8OPlu3t7wLrvqwbkHG3Lh4FsJ7d6T5z56jJfit3AoovTDwwihmzah5+FYTo9qS5eeF9J14Aiax7eh5Ny/xpjaxAJUJamtAapIamo6H3/8Fqpv0KLFd3z//QDGjv3cb95HHhnFeee9W7x98GBz0tJOpaDgVCIjOxAX147mzdvTqlUrGjVqiMsVQKD45Rf47Tc45xwICztarx+/ZvGCp/lt/zZ2HtrNrtz9pEku6ZGQGgW/NvRfXEy+i9Z5UbQurE/7kMZ0i+1At6bdOKV1T2LadSSqdQfCIqL8H2yMqREsQFWS2h6gihQWKuvWfcsnn6TzxhuDSUkpmWfmzM60br0poPKys6NJT29BVlZz8vISWL/+PZo0EeLjnQF88fHQoAHUq7eT+vWV+vVjiY2NISyslBkpVGHjRli2DFatIjMqhO9ahvJtgyw27P+JnzK2siHmCKnR5dctpBDqFYYSSwSxodE0IZpmBVEkFEbTOLwhjWOb0qjhSTRucBKNGjanUVwLGjZtTUzTFrjCrFvRmKpmAaqS1JUA5UnVmddv0SJIToZVq6CwMJMPP2yAyxX870RaWmOGD/e/8vCUKZdx9tmLirdzciLJyYkhLy+a3NwYCgqiKCiIorAwisLCCFQjcVZIieCbb/5JSEgUYWFO4ys+excxh74jr+liMup9xx/5B9mRf4BfNYNdrmxyKCTbBQXH0AMYnQ/1Cl3EFoQQWxhCrIYRQzgxEkm0K5IYVxRRIVFEh8YQFRpFRGgM0SQQEdKMsPB6hEfWJzyyARER9QmPjMQVdYCw8BjCw+sREhaBy3V0zkTPrkrfn0XiCAnxHnFZlCU/f0OJepfW7emdHkFoaHu/+QoKtqOaHXC5nkJCOvnNV1CwB9W0co/3X2YbREq2hAsL0ygs3FOhMl2uZrhcJRfrVs2moCDFKy3QbmSRBoSEJPjdl58f2B97JUUQGtq2lDJ/xZn7OnghIR1L+Xf6I+h/p6KyKnrvOpAAZZOrnaBEoFs35/XQQ87jUevWwbZtL3LkyDdERa2jadOfCQvLC6i8tLSmpe6rVy/dazsiIpuIiGzgQLnl3nXXP8nN9Uw5CTiJe+75iCsvXFnqcXmFkF0AR9yvg7lwMM95/2VhN7Kz8smLTicr6giHonPIjMojM6aAIyFwJBSOUMheCoE8yvwyyHe/ihwu+3oECBUId0FY0Uuc9xBx9oUKhLogJDUc2R6LqzAEV6ELV0EIUui86p+/nZAQCME5LkTA5fHuwv3u83Pu/vpsff9cKAwBdaEagqoLNIRuo/5D/ZMOIO784q5vUS+uZ5p4/gzMn/AIWhjqlIk4ZeKiz/AFdDzrq+Jr93qXo9uC95ecAPP+9j/sTWmPFq0KpE6GU8/6nCHXzzx6bBlfjuLz85J3x7A++QI8VxpSFZq2SmHMY/9T6jLbZX3/fvf5EBbPuKtEuqqLR14fjoR4/8EXyHf5nh1tee2xFzwKO3rUzRPvo2V7/6N0yzP55gVooefML065Q2/8J/2G/CeosiaNWcC2fZeSl+citIoiibWgAlAXW1CByMnJY8uWbaSk/MyBA5vIzd2Oy7WNmJgUGjT4ncjIrOK833wzmPvuW+a3nNdf706HDt9XqA5DhuRTWFhylvZx4+7k8stfrlCZd975VfGaWp6GDn2D+8bfSnYBHC6Aw/nuVwFkFQW7fOfnou3sQsgpgMNbYsnbH05BaB4FIfnkhhWQG1pAdlQBWfWV3ELILXTWeDGmrnBNziInJ7JCAcpaUOaYRESE0bVrJ7p27VRiX2GhcuBAGjt37uTAgT9o3TqS555zHosqeqWlOfPT5uY24eDB5kREHCIy8lDAXYgFBS6/wQkgJCTfb3ogVP3/DStSiEsgOtR5NSljhKGv5z6ZxsKFd5ZIP/nkb3nvtV7F2wUK+YWQp04rL88duPLU2Ve0P19h45d9+fr/huFy5SGuHFwhuYgrF3Hlceb9r6HiBLyi4wrV++dC3O8eP+cejOLA0k7gKgAUpBB1FQJK1NkpSIMcZzlq9zGqzvLUnj/jLks90vK/ckaEqiiKgoCiSOvDaJMcj8/e/c7RsjzL9frN2BYF2a4S6dowD22eW3x+/B3ro2if7A1DMkr+Tml4IQWtckukl1uughxyEbI/zDvd/Z7fNqfkQYHIFUJ2h/ndVZCQh0ZUrGER+uvR+6ue/w0K4/IprBfcn0+hv4Xxa4VqEcQ5qrh8U0e5XEKTJnE0aRIHdCsn95LinwoKCjl8OIvDh49w6NBhsrKOkJ2dRU6O88rLyyE/P4e8vGwKCvJ5+WXIyXG6IHNznff8fIiPv5CtWxsCeagWAAU4fW0FPq9Cj/dCRAro2zeODh2goODoSo0FBdCiRXO2b09EpOjr03l5bvvfB/HxTend+2h5RZo0ieL333sU5/P5qgWcTpYIKZm+Sy8kO+LRo6l69LJ68gUucX+hiG+5nrzT/8jszCsp//ab89ZBIzmpwQ9eaSKBfRFOWrcB1ZJf/Jc0mUTfZrMDKsPXax/OYefO7iXSe/Way2W9J1SozMXrJ/L119eVSG+e8DN3nDncIyXwAPDttyOYv2Sq332PJ52KSPDt5j17OvOvTxf43feX266mRYuK9UgkvfGT33+nSy9Nom+X4P6dJr25gZNPrtoQYl18AThRu/iMMaaqBNLFZ+skGGOMqZEsQBljjKmRLEAZY4ypkSxAGWOMqZEsQBljjKmRLEAZY4ypkSxAGWOMqZHsOagAiMg+qPBD042B/ZVYndrErv3EdKJe+4l63VCxa2+jqk3KymABqoqJyNryHkarq+za7dpPJCfqdUPVXbt18RljjKmRLEAZY4ypkSxAVb1Xq7sC1ciu/cR0ol77iXrdUEXXbvegjDHG1EjWgjLGGFMjWYAyxhhTI1mAqgIi0kpE5opIuohkiMg8EWld3fWqTCJylYj8n4j8KiJZIrJJRJ4UkViffHEi8rqI7BeRwyKyREROq656VwUR+VhEVESm+KTX2WsXkaEi8pmIHHL/jq8VkXM99te5axeRs0XkvyKy133N34jIzT55av11i0hLEfm7iHwhIkfcv9tt/eQL6FpFJFJEnhaR3e7vii9EZGAgdbEAVclEJBpYBnQGRgM3AKcAy0UkpjrrVsnG46zv+jBwEfAv4E7gUxFxAYiIAAvd++8BRgBhOJ9Fy+qodGUTkWuBEsu+1uVrF5HbgQXAOmA4cDXwARDt3l/nrl1ETsdZGjoM+DPONX0NvCEid7rz1JXrPhkYCRwEPveXIchrfQPnM5sIXArsBj4RkR7l1kRV7VWJL2Aszhf3yR5p7XDWI7+3uutXidfZxE/ajThrZZ/r3r7cvT3YI08DIBV4sbqvoRI+g4bAHuBa93VO8dhXJ68daAtkAePKyFPnrh2YCuQC9XzSvwS+qEvXDbg8fr7VfU1tK/JvjPPHmwI3eaSFApuAheXVxVpQle8y4EtV3VKUoKrbgVU4/6h1gqru85P8tfu9hfv9MmCXqi73OC4dWETd+Cz+F9igqrP97Kur134zUAi8XEaeunjt4UAeTnD2lMbRnqg6cd2qWhhAtkCv9TKcz22OR7584D3gQhGJKOskFqAqX1fgRz/pG4Aux7kux9sg9/vP7veyPovWIlLvuNSqCojIAJwW419KyVJXr30AsBH4k4hsFZF8EdkiInd55KmL1z7D/f6iiJwkIg1F5M/AEOA59766eN2lCfRauwLbVfWIn3zhON2JpbIAVfnicfpufaUCcce5LseNiLQAJgNLVHWtO7mszwJq6echImHAK8DfVHVTKdnq5LUDJ+HcU30aeAq4APgUeElExrrz1LlrV9UfgUSc1sFOnOv7B3CHqr7nzlbnrrsMgV5refniyzpJaIWqZsrj7+lnOe61OE7cfy0twLnPdpPnLurmZ/E/QBTwRBl56uq1u4BYYIyqznOnLXOP8npIRF6kDl67iJwC/B/OX/534HT1XQ68LCLZqvoOdfC6yxDotR7TZ2IBqvIdxP9fBXH4/0uiVhORSJzRPO2BQar6u8fuVEr/LKAWfh7uxwUewbl5HOHThx4hIg2BTOrgtbsdwGlBfeqT/l+cEV3NqZvXPhXnXsqlqprnTlsqIo2AF0RkNnXzuksT6LWmAv4esYnz2F8q6+KrfBtw+l19dQF+Os51qVLurq7/A/oBQ1X1B58sZX0WO1T1UBVXsSq0ByKBWTj/CYte4Ay9PwicRt28dnCuy5+iv4gLqZvXfhrwnUdwKrIGaAQ0pW5ed2kCvdYNQDv34ze++XKBLZTBAlTlWwicISLtixLc3R9nu/fVCe5nnd7BuUl8uap+6SfbQqCFiAzyOK4+MIza+1msBwb7eYETtAbj/Keri9cO8G/3+4U+6RcCv6vqHurmte8BeohIuE96fyAbpyVQF6+7NIFe60Kc56Ou9sgXClwD/FdVc8o8S3WPua9rLyAG5wvqB5w+6suA74Bt+DxDUZtfOA/mKjAFOMPn1dKdxwWsBn4D/oTzJZaM85+5VXVfQyV/Hr7PQdXJa8dpKS3D6eq7A2eQxKvu6x9TV68duMp9jZ+4/19fALzkTnu2rl23+3qv8vh/fqd7e1Cw14ozpPwgTrf4EGAuTlDvVW49qvuDqIsvnD7X/wMycO5HzMfnQbfa/gJS3L+4/l5JHvnigenuX9wjwFKge3XXvwo+D68AVZevHaiPM4LtD5xumu+B6+r6tQMXu7+E97n/X6/HecwgpK5ddxn/t5ODvVacAUXP4rRCs4GvgMRA6mHLbRhjjKmR7B6UMcaYGskClDHGmBrJApQxxpgayQKUMcaYGskClDHGmBrJApQxxpgayQKUMQYRSXIv7Z1Y3XUxpogFKGMqgfvLvbxXYnXX05jaxGYzN6ZyTSpjX8rxqoQxdYEFKGMqkaomVXcdjKkrrIvPmGrgec9HREaLyLcikiUie0VkuogklHLcKSLylojsFJFcEdnl3j6llPwhInKHiKwSkXT3ObaIyOtlHHOViKwRkSMikioi77lXTPbN115EXnWXl+XO+4OIvOxeJ8mYY2ItKGOq119xZsaeA3wMDMBZlThRRPqr6r6ijCLSF1iCs6LtQpz1xToDo4DLRWSIqq71yB8OLAbOw5l1+l2cCYzbAsOBlcAvPvX5C84M/AuBFTjLSVwDdBeRHupeHkFEmgNf40wc+x+cyZEjgXbADTgzfR845k/HnNAsQBlTiUQkqZRd2ar6lJ/0i4H+qvqtRxnPAeOAp4Bb3GkCvIUTEK5XZ4nxovzX4CxpMEtEuqhqoXtXEk5wWgRcrR5r77hXAq7vpz4XAX3VY/FJEXkXuBZnmYn33clX4cxmPU5VX/D5DGJwFi405phYgDKmcj1WSno6TsDx9bZncHJLwmlFXScif3EHlrNwWktfeAYnAFWdIyJ347S+BgCfiUgITmsoC7hDfRaGc2/vo6QXteTKyK/hBKh+HA1QRbJ8C1DVw37KNSZodg/KmEqkqlLKq2Eph6zwU0Y6zlpDkcCp7uRe7vdlpZRTlN7T/d4ZaAB8r6q7griEtX7SfnO/x3mkLQQOAf8Qkf8TkdtEpKu7pWdMpbAAZUz1+qOU9D3u9wY+77tLyV+U3tDnfWeQ9Unzk5bvfg8pSlDVX3FaVPNwuhFfAX4EfhWR/xfkOY3xywKUMdWrWSnpRaP40n3e/Y7uA5r75Etzv5cYfVdZVPVnVb0GaAT0AR7E+U55QURuqarzmhOHBShjqtcg3wQRaQD0wFke+2d3ctF9qsRSyilK/8b9vhEnSJ0uIicdezVLp6r5qrpOVafh3KsCuKIqz2lODBagjKleN4hIT5+0JJwuvdkegxtWAZuAASJylWdm9/ZAYDPO0HFUtQD4JxAFvOweted5TLiINKlopUWkn4j4a/0VpR2paNnGFLFRfMZUojKGmQPMV9X1PmkfAatE5H2c+0hFI/FScLrMAFBVFZHRwKfAHBFZgNNK6oTTWskEbvQYYg7OtEv9gWHAZhH50J2vFc6zV/cDMypwmQDXAXeJyApgC3AQ6OA+Vw7wfAXLNaaYBShjKldpw8zBCTrrfdKeA/6N89zTNTgj42YAD6vqXs+MqvqV+2HdCTgDE4YB+4HZwOOqusknf66IXATcAdwIjAYE2OU+58pgL87DbCACZ/h7L5yW2k6c57GeUdUfj6FsYwAQVa3uOhhzwnG3tB4DBqtqcvXWxpiaye5BGWOMqZEsQBljjKmRLEAZY4ypkewelDHGmBrJWlDGGGNqJAtQxhhjaiQLUMYYY2okC1DGGGNqJAtQxhhjaqT/D9XF3hudWbjaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "\n",
    "epochs_gd_1 = range(len(objvals_gd_q1))\n",
    "epochs_sgd_1 = range(len(objvals_sgd_q1))\n",
    "\n",
    "epochs_gd_2 = range(len(objvals_gd_q8))\n",
    "epochs_sgd_2 = range(len(objvals_sgd_q8))\n",
    "\n",
    "line0, = plt.plot(epochs_gd_1, objvals_gd_q1, '-b', LineWidth=4)\n",
    "line1, = plt.plot(epochs_sgd_1, objvals_sgd_q1, '-r', LineWidth=2)\n",
    "line2, = plt.plot(epochs_gd_2, objvals_gd_q8, '--y', LineWidth=4)\n",
    "line3, = plt.plot(epochs_sgd_2, objvals_sgd_q8, '-g', LineWidth=2)\n",
    "plt.xlabel('Epochs', FontSize=20)\n",
    "plt.ylabel('Objective Value', FontSize=20)\n",
    "plt.xticks(FontSize=16)\n",
    "plt.yticks(FontSize=16)\n",
    "plt.legend([line0, line1, line2, line3], ['GDq1', 'SGDq1', 'GDq8', 'SGDq8'], fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('compare_gd_sgd.pdf', format='pdf', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
